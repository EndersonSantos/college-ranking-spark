{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38fd3425-fc77-4155-b970-63386b247b90",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Projeto PBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "362ecfbb-8033-45df-a055-f033a0223783",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing PySpark ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 10:17:43 WARN Utils: Your hostname, DESKTOP-M9FP7G5 resolves to a loopback address: 127.0.1.1; using 192.168.89.130 instead (on interface eth0)\n",
      "23/03/23 10:17:43 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/03/23 10:17:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.89.130:4040\n",
       "SparkContext available as 'sc' (version = 3.3.1, master = local[*], app id = local-1679566669565)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from ydata_profiling import ProfileReport\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e416407-1dd4-468c-8d90-d574e9e9fd89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b0e9eaf-cc20-4408-9b96-1099e478f7c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 10:18:27 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# build our own SparkSession\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"BigData\")\\\n",
    "    .config(\"spark.sql.shuffle.partitions\",6)\\\n",
    "    .config(\"spark.sql.repl.eagereval.enabled\",True)\\\n",
    "    .getOrCreate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "329a1522-05be-4f3d-8173-f5c070ffdd0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.89.130:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession object at 0x7f72526d0f10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69aee9e-b38f-495a-bc9c-e602cd20a4e7",
   "metadata": {},
   "source": [
    "### 1ÂªInicio\n",
    "* Read CSV\n",
    "* Perform EDA\n",
    "\n",
    "\t- Understand the problem\n",
    "\t- Which one makes sense to keep for Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b471065c-2cd7-443a-86bc-34f016ccb6e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date_time,site_name,posa_continent,user_location_country,user_location_region,user_location_city,orig_destination_distance,user_id,is_mobile,is_package,channel,srch_ci,srch_co,srch_adults_cnt,srch_children_cnt,srch_rm_cnt,srch_destination_id,srch_destination_type_id,is_booking,cnt,hotel_continent,hotel_country,hotel_market,hotel_cluster\n",
      "2014-08-11 07:46:59,2,3,66,348,48862,2234.2641,12,0,1,9,2014-08-27,2014-08-31,2,0,1,8250,1,0,3,2,50,628,1\n",
      "\n",
      "2014-09-18 08:52:42,2,3,66,462,12565,106.4274,1198182,0,0,0,2014-09-18,2014-09-19,1,0,1,18811,1,1,1,2,50,592,42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! head -n 2 train.csv\n",
    "! tail -n 1 train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6c9032e-f749-4460-b639-c74c3a16eece",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = 'train.csv'\n",
    "df_hotels =  spark.read.csv(filename, header=True, inferSchema=\"true\", sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a0c4f9-51b2-4f0a-8c61-b0a3928c4e8d",
   "metadata": {},
   "source": [
    "### Check DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca5574fc-bbdb-43bc-b206-dc559b6ab166",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_time: timestamp (nullable = true)\n",
      " |-- site_name: integer (nullable = true)\n",
      " |-- posa_continent: integer (nullable = true)\n",
      " |-- user_location_country: integer (nullable = true)\n",
      " |-- user_location_region: integer (nullable = true)\n",
      " |-- user_location_city: integer (nullable = true)\n",
      " |-- orig_destination_distance: double (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- is_mobile: integer (nullable = true)\n",
      " |-- is_package: integer (nullable = true)\n",
      " |-- channel: integer (nullable = true)\n",
      " |-- srch_ci: timestamp (nullable = true)\n",
      " |-- srch_co: timestamp (nullable = true)\n",
      " |-- srch_adults_cnt: integer (nullable = true)\n",
      " |-- srch_children_cnt: integer (nullable = true)\n",
      " |-- srch_rm_cnt: integer (nullable = true)\n",
      " |-- srch_destination_id: integer (nullable = true)\n",
      " |-- srch_destination_type_id: integer (nullable = true)\n",
      " |-- is_booking: integer (nullable = true)\n",
      " |-- cnt: integer (nullable = true)\n",
      " |-- hotel_continent: integer (nullable = true)\n",
      " |-- hotel_country: integer (nullable = true)\n",
      " |-- hotel_market: integer (nullable = true)\n",
      " |-- hotel_cluster: integer (nullable = true)\n",
      "\n",
      "-RECORD 0----------------------------------------\n",
      " date_time                 | 2014-08-11 07:46:59 \n",
      " site_name                 | 2                   \n",
      " posa_continent            | 3                   \n",
      " user_location_country     | 66                  \n",
      " user_location_region      | 348                 \n",
      " user_location_city        | 48862               \n",
      " orig_destination_distance | 2234.2641           \n",
      " user_id                   | 12                  \n",
      " is_mobile                 | 0                   \n",
      " is_package                | 1                   \n",
      " channel                   | 9                   \n",
      " srch_ci                   | 2014-08-27 00:00:00 \n",
      " srch_co                   | 2014-08-31 00:00:00 \n",
      " srch_adults_cnt           | 2                   \n",
      " srch_children_cnt         | 0                   \n",
      " srch_rm_cnt               | 1                   \n",
      " srch_destination_id       | 8250                \n",
      " srch_destination_type_id  | 1                   \n",
      " is_booking                | 0                   \n",
      " cnt                       | 3                   \n",
      " hotel_continent           | 2                   \n",
      " hotel_country             | 50                  \n",
      " hotel_market              | 628                 \n",
      " hotel_cluster             | 1                   \n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37670293"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hotels.printSchema()\n",
    "df_hotels.show(1, vertical=True)\n",
    "hotels_count = df_hotels.count()\n",
    "hotels_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d1471d-6548-4a26-bff3-493d8a88ce80",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Evaluate DATA**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8994664f",
   "metadata": {},
   "source": [
    "### Drop column User_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3026e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotels = df_hotels.drop('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee58728",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotels.show(1, vertical = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c43a6688",
   "metadata": {},
   "source": [
    "### Create a number off nights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838e01b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotels=df_hotels.withColumn(\"n_of_nights\", datediff(F.col(\"srch_co\"),F.col(\"srch_ci\"))-1)\n",
    "df_hotels.show(3,vertical=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f352b92",
   "metadata": {},
   "source": [
    "### **Id hotel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cc34a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotels = df_hotels.withColumn('Id_hotel', \n",
    "                    F.concat(F.col('hotel_cluster'),F.lit('_'), F.col('hotel_market'),F.lit('_'), F.col('hotel_country'),F.lit('_'), F.col('hotel_continent')))\n",
    "df_hotels.show(5,vertical = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7b41d5-fbb2-4a9c-9030-a3f1de4aca45",
   "metadata": {},
   "source": [
    "### **NULLS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f01b3ffd-47da-4f66-ac5e-c5020d544588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nulls in Hotels:\n",
      "Column orig_destination_distance with 13525001 nulls or NaN, out of 37670293 records (35.90%)\n"
     ]
    }
   ],
   "source": [
    "print('\\nNulls in Hotels:')\n",
    "cols_to_forget = ['date_time','srch_ci','srch_co']\n",
    "hotels_cols_interest = [x for x in df_hotels.columns if x not in cols_to_forget]\n",
    "for cl in hotels_cols_interest:\n",
    "    k = df_hotels.select(cl).filter(F.col(cl).isNull() | F.isnan(cl)).count()\n",
    "    if k > 0:\n",
    "        print(f'Column {cl} with {k} nulls or NaN, out of {hotels_count} records ({k*100/hotels_count:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d566d24-2350-4371-96e6-712d10c90a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels_cols_interest.remove('orig_destination_distance')\n",
    "df_hotels = hotels_cols_interest.remove('orig_destination_distance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfa1e98-0ca7-4eb9-a01f-56acbf51427c",
   "metadata": {},
   "source": [
    "### **Summary to figure out outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b6ff29a-646a-445f-a6b2-05eb332b895f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0----------------------------------------\n",
      " summary                   | count               \n",
      " site_name                 | 37670293            \n",
      " posa_continent            | 37670293            \n",
      " user_location_country     | 37670293            \n",
      " user_location_region      | 37670293            \n",
      " user_location_city        | 37670293            \n",
      " orig_destination_distance | 24145292            \n",
      " user_id                   | 37670293            \n",
      " is_mobile                 | 37670293            \n",
      " is_package                | 37670293            \n",
      " channel                   | 37670293            \n",
      " srch_adults_cnt           | 37670293            \n",
      " srch_children_cnt         | 37670293            \n",
      " srch_rm_cnt               | 37670293            \n",
      " srch_destination_id       | 37670293            \n",
      " srch_destination_type_id  | 37670293            \n",
      " is_booking                | 37670293            \n",
      " cnt                       | 37670293            \n",
      " hotel_continent           | 37670293            \n",
      " hotel_country             | 37670293            \n",
      " hotel_market              | 37670293            \n",
      " hotel_cluster             | 37670293            \n",
      "-RECORD 1----------------------------------------\n",
      " summary                   | mean                \n",
      " site_name                 | 9.795271329585889   \n",
      " posa_continent            | 2.6804730188851997  \n",
      " user_location_country     | 86.10880194109454   \n",
      " user_location_region      | 308.4060117610447   \n",
      " user_location_city        | 27753.044729330883  \n",
      " orig_destination_distance | 1970.0900267207285  \n",
      " user_id                   | 604451.7531778422   \n",
      " is_mobile                 | 0.1349265056154461  \n",
      " is_package                | 0.24890422275186444 \n",
      " channel                   | 5.8707613981128315  \n",
      " srch_adults_cnt           | 2.0242958290767743  \n",
      " srch_children_cnt         | 0.3321221579030458  \n",
      " srch_rm_cnt               | 1.1126628083301608  \n",
      " srch_destination_id       | 14441.090543760836  \n",
      " srch_destination_type_id  | 2.5822799148389954  \n",
      " is_booking                | 0.07965674702875288 \n",
      " cnt                       | 1.4833839227106622  \n",
      " hotel_continent           | 3.1563047837190967  \n",
      " hotel_country             | 81.29685165974153   \n",
      " hotel_market              | 600.461883638654    \n",
      " hotel_cluster             | 49.80860501934509   \n",
      "-RECORD 2----------------------------------------\n",
      " summary                   | stddev              \n",
      " site_name                 | 11.9675435665128    \n",
      " posa_continent            | 0.7480393482506577  \n",
      " user_location_country     | 59.24310334783878   \n",
      " user_location_region      | 208.44374973856722  \n",
      " user_location_city        | 16782.553195680346  \n",
      " orig_destination_distance | 2232.4424303904275  \n",
      " user_id                   | 350617.4620408585   \n",
      " is_mobile                 | 0.34164505966916764 \n",
      " is_package                | 0.43237820899182056 \n",
      " channel                   | 3.71709455862911    \n",
      " srch_adults_cnt           | 0.9116678125665977  \n",
      " srch_children_cnt         | 0.7314980986397146  \n",
      " srch_rm_cnt               | 0.45911549963856946 \n",
      " srch_destination_id       | 11066.302332627309  \n",
      " srch_destination_type_id  | 2.153018959399955   \n",
      " is_booking                | 0.2707610600283715  \n",
      " cnt                       | 1.2197755786558424  \n",
      " hotel_continent           | 1.6231886782105662  \n",
      " hotel_country             | 56.171188062887815  \n",
      " hotel_market              | 511.73912727922396  \n",
      " hotel_cluster             | 28.915950805004293  \n",
      "-RECORD 3----------------------------------------\n",
      " summary                   | min                 \n",
      " site_name                 | 2                   \n",
      " posa_continent            | 0                   \n",
      " user_location_country     | 0                   \n",
      " user_location_region      | 0                   \n",
      " user_location_city        | 0                   \n",
      " orig_destination_distance | 0.0056              \n",
      " user_id                   | 0                   \n",
      " is_mobile                 | 0                   \n",
      " is_package                | 0                   \n",
      " channel                   | 0                   \n",
      " srch_adults_cnt           | 0                   \n",
      " srch_children_cnt         | 0                   \n",
      " srch_rm_cnt               | 0                   \n",
      " srch_destination_id       | 0                   \n",
      " srch_destination_type_id  | 0                   \n",
      " is_booking                | 0                   \n",
      " cnt                       | 1                   \n",
      " hotel_continent           | 0                   \n",
      " hotel_country             | 0                   \n",
      " hotel_market              | 0                   \n",
      " hotel_cluster             | 0                   \n",
      "-RECORD 4----------------------------------------\n",
      " summary                   | max                 \n",
      " site_name                 | 53                  \n",
      " posa_continent            | 4                   \n",
      " user_location_country     | 239                 \n",
      " user_location_region      | 1027                \n",
      " user_location_city        | 56508               \n",
      " orig_destination_distance | 12407.9022          \n",
      " user_id                   | 1198785             \n",
      " is_mobile                 | 1                   \n",
      " is_package                | 1                   \n",
      " channel                   | 10                  \n",
      " srch_adults_cnt           | 9                   \n",
      " srch_children_cnt         | 9                   \n",
      " srch_rm_cnt               | 8                   \n",
      " srch_destination_id       | 65107               \n",
      " srch_destination_type_id  | 9                   \n",
      " is_booking                | 1                   \n",
      " cnt                       | 269                 \n",
      " hotel_continent           | 6                   \n",
      " hotel_country             | 212                 \n",
      " hotel_market              | 2117                \n",
      " hotel_cluster             | 99                  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_hotels.describe(hotels_cols_interest).show(vertical = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf3d636-7a86-4ce3-ba7c-ab3f61bc839a",
   "metadata": {},
   "source": [
    "### **UNIQUENESS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faabc16b-7463-4417-936e-38d559a82525",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uniqueness in Hotels:\n",
      "Column site_name with 45 distinct values, out of 37670293 records (0.00%)\n",
      "Column posa_continent with 5 distinct values, out of 37670293 records (0.00%)\n",
      "Column user_location_country with 237 distinct values, out of 37670293 records (0.00%)\n",
      "Column user_location_region with 1008 distinct values, out of 37670293 records (0.00%)\n",
      "Column user_location_city with 50447 distinct values, out of 37670293 records (0.13%)\n",
      "Column orig_destination_distance with 8495290 distinct values, out of 37670293 records (22.55%)\n",
      "Column user_id with 1198786 distinct values, out of 37670293 records (3.18%)\n",
      "Column is_mobile with 2 distinct values, out of 37670293 records (0.00%)\n",
      "Column is_package with 2 distinct values, out of 37670293 records (0.00%)\n",
      "Column channel with 11 distinct values, out of 37670293 records (0.00%)\n",
      "Column srch_adults_cnt with 10 distinct values, out of 37670293 records (0.00%)\n",
      "Column srch_children_cnt with 10 distinct values, out of 37670293 records (0.00%)\n",
      "Column srch_rm_cnt with 9 distinct values, out of 37670293 records (0.00%)\n",
      "Column srch_destination_id with 59455 distinct values, out of 37670293 records (0.16%)\n",
      "Column srch_destination_type_id with 10 distinct values, out of 37670293 records (0.00%)\n",
      "Column is_booking with 2 distinct values, out of 37670293 records (0.00%)\n",
      "Column cnt with 104 distinct values, out of 37670293 records (0.00%)\n",
      "Column hotel_continent with 7 distinct values, out of 37670293 records (0.00%)\n",
      "Column hotel_country with 213 distinct values, out of 37670293 records (0.00%)\n",
      "Column hotel_market with 2118 distinct values, out of 37670293 records (0.01%)\n",
      "Column hotel_cluster with 100 distinct values, out of 37670293 records (0.00%)\n"
     ]
    }
   ],
   "source": [
    "print('\\nUniqueness in Hotels:')\n",
    "for cl in hotels_cols_interest:\n",
    "    k = df_hotels.select(cl).distinct().count()\n",
    "    if k > 0:\n",
    "        print(f'Column {cl} with {k} distinct values, out of {hotels_count} records ({k*100/hotels_count:.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc31664-266c-4907-ad5d-6124ba034eb1",
   "metadata": {},
   "source": [
    "### **Saving clean data**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e68e18c-7d99-459f-84de-be2224ea0ab6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376623"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 5\n",
    "with_replacement = False\n",
    "fraction = 0.01          \n",
    "small_df_hotels = df_hotels.sample(withReplacement=with_replacement, \n",
    "                                               fraction=fraction, seed=seed)\n",
    "small_df_hotels.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17782d9b-9361-468f-a754-b138a2e52c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df_hotels.write.mode(\"overwrite\").parquet(\"small-hotels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47e0a04-0e68-4966-b8a7-281e2598b689",
   "metadata": {},
   "source": [
    "### **Final Overview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "690ef7f1-d4d6-4fc8-9076-50085c006bf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_clean = small_df_hotels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f8c1877-fe35-44bc-8256-3eb678487773",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "376623"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotels_count = df_clean.count()\n",
    "hotels_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c49fc883-9883-4f3f-87f6-a2106f4df316",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['site_name', 'posa_continent', 'user_location_country', 'user_location_region', 'user_location_city', 'orig_destination_distance', 'user_id', 'is_mobile', 'is_package', 'channel', 'srch_adults_cnt', 'srch_children_cnt', 'srch_rm_cnt', 'srch_destination_id', 'srch_destination_type_id', 'is_booking', 'cnt', 'hotel_continent', 'hotel_country', 'hotel_market', 'hotel_cluster']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_forget = ['date_time','srch_ci','srch_co']\n",
    "hotels_cols_interest = [x for x in df_clean.columns if x not in cols_to_forget]\n",
    "hotels_cols_interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f36257-3c2f-4c64-ae67-54ff28112443",
   "metadata": {},
   "source": [
    "### **Descriptive statistics about the data to be used in the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d192a5d8-6833-4963-b374-018622b98cba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Nulls in Transactions:\n",
      "Column orig_destination_distance with 135295 nulls or NaN, out of 376623 records (35.92%)\n"
     ]
    }
   ],
   "source": [
    "print('\\nNulls in Transactions:')\n",
    "for cl in hotels_cols_interest:\n",
    "    k = df_clean.select(cl).filter(F.col(cl).isNull() | F.isnan(cl)).count()\n",
    "    if k > 0:\n",
    "        print(f'Column {cl} with {k} nulls or NaN, out of {hotels_count} records ({k*100/hotels_count:.2f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54b84aaa-c795-4442-a3c4-04ae55d3f1c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date_time: timestamp (nullable = true)\n",
      " |-- site_name: integer (nullable = true)\n",
      " |-- posa_continent: integer (nullable = true)\n",
      " |-- user_location_country: integer (nullable = true)\n",
      " |-- user_location_region: integer (nullable = true)\n",
      " |-- user_location_city: integer (nullable = true)\n",
      " |-- orig_destination_distance: double (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- is_mobile: integer (nullable = true)\n",
      " |-- is_package: integer (nullable = true)\n",
      " |-- channel: integer (nullable = true)\n",
      " |-- srch_ci: timestamp (nullable = true)\n",
      " |-- srch_co: timestamp (nullable = true)\n",
      " |-- srch_adults_cnt: integer (nullable = true)\n",
      " |-- srch_children_cnt: integer (nullable = true)\n",
      " |-- srch_rm_cnt: integer (nullable = true)\n",
      " |-- srch_destination_id: integer (nullable = true)\n",
      " |-- srch_destination_type_id: integer (nullable = true)\n",
      " |-- is_booking: integer (nullable = true)\n",
      " |-- cnt: integer (nullable = true)\n",
      " |-- hotel_continent: integer (nullable = true)\n",
      " |-- hotel_country: integer (nullable = true)\n",
      " |-- hotel_market: integer (nullable = true)\n",
      " |-- hotel_cluster: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_clean.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08094341-e2d0-4c25-801d-bbca675d200d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# few distincts\n",
    "cls_1 = ['site_name', 'user_id', 'is_mobile', 'srch_adults_cnt', 'hotel_cluster', 'is_booking']\n",
    "\n",
    "# numeric types but no nulls\n",
    "cls_2 = ['site_name', 'user_id', 'is_mobile', 'srch_adults_cnt', 'hotel_cluster', 'is_booking', 'hotel_country', 'srch_destination_id', 'is_package']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49699482-b2fc-43de-ba6e-934eee982ae6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uniqueness in Transactions:\n",
      "+---------+\n",
      "|site_name|\n",
      "+---------+\n",
      "|2        |\n",
      "|5        |\n",
      "|6        |\n",
      "|7        |\n",
      "|8        |\n",
      "|9        |\n",
      "|10       |\n",
      "|11       |\n",
      "|13       |\n",
      "|14       |\n",
      "|15       |\n",
      "|16       |\n",
      "|17       |\n",
      "|18       |\n",
      "|19       |\n",
      "|20       |\n",
      "|21       |\n",
      "|22       |\n",
      "|23       |\n",
      "|24       |\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+\n",
      "|user_id|\n",
      "+-------+\n",
      "|4      |\n",
      "|8      |\n",
      "|11     |\n",
      "|13     |\n",
      "|15     |\n",
      "|31     |\n",
      "|36     |\n",
      "|40     |\n",
      "|47     |\n",
      "|52     |\n",
      "|62     |\n",
      "|74     |\n",
      "|81     |\n",
      "|86     |\n",
      "|89     |\n",
      "|103    |\n",
      "|105    |\n",
      "|114    |\n",
      "|116    |\n",
      "|119    |\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+---------+\n",
      "|is_mobile|\n",
      "+---------+\n",
      "|0        |\n",
      "|1        |\n",
      "+---------+\n",
      "\n",
      "+---------------+\n",
      "|srch_adults_cnt|\n",
      "+---------------+\n",
      "|0              |\n",
      "|1              |\n",
      "|2              |\n",
      "|3              |\n",
      "|4              |\n",
      "|5              |\n",
      "|6              |\n",
      "|7              |\n",
      "|8              |\n",
      "|9              |\n",
      "+---------------+\n",
      "\n",
      "+-------------+\n",
      "|hotel_cluster|\n",
      "+-------------+\n",
      "|0            |\n",
      "|1            |\n",
      "|2            |\n",
      "|3            |\n",
      "|4            |\n",
      "|5            |\n",
      "|6            |\n",
      "|7            |\n",
      "|8            |\n",
      "|9            |\n",
      "|10           |\n",
      "|11           |\n",
      "|12           |\n",
      "|13           |\n",
      "|14           |\n",
      "|15           |\n",
      "|16           |\n",
      "|17           |\n",
      "|18           |\n",
      "|19           |\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+\n",
      "|is_booking|\n",
      "+----------+\n",
      "|0         |\n",
      "|1         |\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\nUniqueness in Transactions:')\n",
    "for cl in cls_1:\n",
    "    df_clean.select(cl).distinct().sort(cl).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba047dc-9fbe-458c-ad24-04358b857412",
   "metadata": {},
   "source": [
    "### **Correlations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "041f8485-dc29-4358-86ee-da72c10eb328",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plotHistogram(df, xcol, huecol=None):\n",
    "    sns.histplot(data=df, x=xcol, hue=huecol, multiple=\"stack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3e28111-d46d-4dc3-922e-62d54e474907",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot(df, xcol, ycol):\n",
    "    sns.lineplot(data=df, x=xcol, y=ycol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d394e4e-9dd4-4305-a454-517b02e7e7e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plotBar(df, xcol, ycol, huecol=None):\n",
    "    sns.barplot(data=df, x=xcol, y=ycol, hue=huecol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cfdf73ac-710f-4829-a4be-d2bbc8d1130a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plotScatter(df, xcol, ycol, huecol=None):\n",
    "    sns.scatterplot(data=df, x=xcol, y=ycol, hue=huecol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c19560b-d2aa-4b96-bc95-b6945ed6d4f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plotScatterMatrix(df, huecol=None):\n",
    "    sns.pairplot(data=df, hue=huecol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3d03a3b-6aaf-45c5-b944-f9ecd2881fbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plotCorrelationMatrix_1(df, annot=False):\n",
    "    # compute the correlation matrix\n",
    "    corr = df.corr()\n",
    "    \n",
    "    # generate a mask for the upper triangle\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "    # set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "    # generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "    #cmap='coolwarm'\n",
    "\n",
    "    # draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, annot=annot,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c532db6-e273-4696-bd3a-b2b5576440b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plotCorrelationMatrix_2(df):\n",
    "    # compute a correlation matrix and convert to long-form\n",
    "    corr_mat = df.corr().stack().reset_index(name=\"correlation\")\n",
    "    # draw each cell as a scatter point with varying size and color\n",
    "    g = sns.relplot(\n",
    "        data=corr_mat,\n",
    "        x=\"level_0\", y=\"level_1\", hue=\"correlation\", size=\"correlation\",\n",
    "        palette=\"vlag\", hue_norm=(-1, 1), edgecolor=\".7\",\n",
    "        height=10, sizes=(50, 250), size_norm=(-.2, .8),\n",
    "    )\n",
    "\n",
    "    # tweak the figure to finalize\n",
    "    g.set(xlabel=\"\", ylabel=\"\", aspect=\"equal\")\n",
    "    g.despine(left=True, bottom=True)\n",
    "    g.ax.margins(.02)\n",
    "    for label in g.ax.get_xticklabels():\n",
    "        label.set_rotation(90)\n",
    "    for artist in g.legend.legendHandles:\n",
    "        artist.set_edgecolor(\".7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3becdda7-1e14-4393-bb37-6074645aeb7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/23 11:57:27 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/03/23 11:57:27 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    }
   ],
   "source": [
    "cols_corr = cls_2\n",
    "\n",
    "vector_col = \"corr_features\"\n",
    "assembler = VectorAssembler(inputCols=cols_corr, outputCol=vector_col)\n",
    "df_vector = assembler.transform(df_clean).select(vector_col)\n",
    "\n",
    "# get correlation matrix - it can be Pearsonâs (default) or Spearmanâs correlation\n",
    "\n",
    "# corr = Correlation.corr(df_vector, vector_col).head()\n",
    "# print(\"Pearson correlation matrix:\\n\" + str(corr[0]))\n",
    "\n",
    "# corr = Correlation.corr(df_vector, vector_col, \"spearman\").head()\n",
    "# print(\"Spearman correlation matrix:\\n\" + str(corr[0]))\n",
    "\n",
    "corr_matrix = Correlation.corr(df_vector, vector_col).collect()[0][0].toArray().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "936c5073-3943-4932-afd4-69cb2628b658",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_plot = pd.DataFrame(data = corr_matrix, index=cols_corr, columns=cols_corr)\n",
    "plotCorrelationMatrix_1(df_plot, annot=True)\n",
    "plt.title('Correlations among numerical features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f72d9a8-4400-4a55-8b9f-5cbdaae9c199",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hotel_cluster</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hotel_cluster  count\n",
       "0              0   3748\n",
       "1              1   4440\n",
       "2              2   4406\n",
       "3              3   2231\n",
       "4              4   3504"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_plot = ( df_clean\n",
    "                .groupby('hotel_cluster')\n",
    "                .count()\n",
    "                .sort('hotel_cluster', ascending=True)\n",
    "                .toPandas()\n",
    "          )\n",
    "plotBar(df_plot, 'hotel_cluster', 'count')\n",
    "plt.title('Number of transactions by year')\n",
    "plt.show()\n",
    "df_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b5e65d-1e61-43b5-b470-12cb8bb10add",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_plot = ( df_clean\n",
    "            .groupby(['Year', 'Month'])\n",
    "            .count()\n",
    "            .withColumn('Year - Month', F.concat('Year', 'Month'))\n",
    "            #.sort('Year - Month', ascending=True)\n",
    "            .toPandas()\n",
    "          )\n",
    "df_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656a360f-9aaf-4dfb-966a-00359929b06a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1da1e91-168a-449a-ba7f-3a23c206c23f",
   "metadata": {},
   "source": [
    "### **Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3289236-39fe-4db2-a216-f52e86837cf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/22 19:53:02 WARN BlockManager: Block rdd_403_2 could not be removed as it was not found on disk or in memory\n",
      "23/03/22 19:53:02 WARN BlockManager: Block rdd_404_2 could not be removed as it was not found on disk or in memory\n",
      "23/03/22 19:53:02 WARN BlockManager: Block rdd_403_1 could not be removed as it was not found on disk or in memory\n",
      "23/03/22 19:53:02 WARN BlockManager: Block rdd_404_1 could not be removed as it was not found on disk or in memory\n",
      "23/03/22 19:53:02 ERROR Executor: Exception in task 2.0 in stage 201.0 (TID 1540)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.base/java.util.Arrays.copyOf(Arrays.java:3865)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.mkArray(ArrayBuilder.scala:471)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.resize(ArrayBuilder.scala:475)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.ensureSize(ArrayBuilder.scala:487)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$eq(ArrayBuilder.scala:492)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$eq(ArrayBuilder.scala:462)\n",
      "\tat scala.collection.generic.Growable.$anonfun$$plus$plus$eq$1(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable$$Lambda$20/0x000000084009b840.apply(Unknown Source)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofFloat.foreach(ArrayOps.scala:270)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$plus$eq(ArrayBuilder.scala:505)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$plus$eq(ArrayBuilder.scala:462)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$UncompressedInBlockBuilder.add(ALS.scala:1426)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$makeBlocks$6(ALS.scala:1643)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$4147/0x00000008415d9040.apply(Unknown Source)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.util.collection.CompactBuffer$$anon$1.foreach(CompactBuffer.scala:115)\n",
      "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
      "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
      "\tat org.apache.spark.util.collection.CompactBuffer.foreach(CompactBuffer.scala:32)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$makeBlocks$5(ALS.scala:1642)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$4143/0x00000008415ec040.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$mapValues$3(PairRDDFunctions.scala:752)\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions$$Lambda$4124/0x00000008415ea040.apply(Unknown Source)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1518)\n",
      "23/03/22 19:53:02 ERROR Executor: Exception in task 1.0 in stage 201.0 (TID 1539)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.base/java.util.Arrays.copyOf(Arrays.java:3793)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofInt.mkArray(ArrayBuilder.scala:339)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofInt.resize(ArrayBuilder.scala:343)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofInt.ensureSize(ArrayBuilder.scala:355)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofInt.$plus$eq(ArrayBuilder.scala:360)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofInt.$plus$eq(ArrayBuilder.scala:330)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$UncompressedInBlockBuilder.add(ALS.scala:1429)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$makeBlocks$6(ALS.scala:1643)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$4147/0x00000008415d9040.apply(Unknown Source)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.util.collection.CompactBuffer$$anon$1.foreach(CompactBuffer.scala:115)\n",
      "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
      "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
      "\tat org.apache.spark.util.collection.CompactBuffer.foreach(CompactBuffer.scala:32)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$makeBlocks$5(ALS.scala:1642)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$4143/0x00000008415ec040.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$mapValues$3(PairRDDFunctions.scala:752)\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions$$Lambda$4124/0x00000008415ea040.apply(Unknown Source)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1518)\n",
      "\tat org.apache.spark.storage.BlockManager$$Lambda$2292/0x0000000840fcb040.apply(Unknown Source)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1445)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1509)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1332)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:378)\n",
      "23/03/22 19:53:02 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 1.0 in stage 201.0 (TID 1539),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.base/java.util.Arrays.copyOf(Arrays.java:3793)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofInt.mkArray(ArrayBuilder.scala:339)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofInt.resize(ArrayBuilder.scala:343)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofInt.ensureSize(ArrayBuilder.scala:355)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofInt.$plus$eq(ArrayBuilder.scala:360)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofInt.$plus$eq(ArrayBuilder.scala:330)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$UncompressedInBlockBuilder.add(ALS.scala:1429)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$makeBlocks$6(ALS.scala:1643)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$4147/0x00000008415d9040.apply(Unknown Source)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.util.collection.CompactBuffer$$anon$1.foreach(CompactBuffer.scala:115)\n",
      "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
      "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
      "\tat org.apache.spark.util.collection.CompactBuffer.foreach(CompactBuffer.scala:32)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$makeBlocks$5(ALS.scala:1642)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$4143/0x00000008415ec040.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$mapValues$3(PairRDDFunctions.scala:752)\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions$$Lambda$4124/0x00000008415ea040.apply(Unknown Source)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1518)\n",
      "\tat org.apache.spark.storage.BlockManager$$Lambda$2292/0x0000000840fcb040.apply(Unknown Source)\n",
      "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1445)\n",
      "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1509)\n",
      "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1332)\n",
      "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:376)\n",
      "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:327)\n",
      "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n",
      "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:365)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:378)\n",
      "23/03/22 19:53:02 ERROR SparkUncaughtExceptionHandler: Uncaught exception in thread Thread[Executor task launch worker for task 2.0 in stage 201.0 (TID 1540),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.base/java.util.Arrays.copyOf(Arrays.java:3865)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.mkArray(ArrayBuilder.scala:471)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.resize(ArrayBuilder.scala:475)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.ensureSize(ArrayBuilder.scala:487)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$eq(ArrayBuilder.scala:492)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$eq(ArrayBuilder.scala:462)\n",
      "\tat scala.collection.generic.Growable.$anonfun$$plus$plus$eq$1(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable$$Lambda$20/0x000000084009b840.apply(Unknown Source)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofFloat.foreach(ArrayOps.scala:270)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$plus$eq(ArrayBuilder.scala:505)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$plus$eq(ArrayBuilder.scala:462)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$UncompressedInBlockBuilder.add(ALS.scala:1426)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$makeBlocks$6(ALS.scala:1643)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$4147/0x00000008415d9040.apply(Unknown Source)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.util.collection.CompactBuffer$$anon$1.foreach(CompactBuffer.scala:115)\n",
      "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
      "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
      "\tat org.apache.spark.util.collection.CompactBuffer.foreach(CompactBuffer.scala:32)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$makeBlocks$5(ALS.scala:1642)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$4143/0x00000008415ec040.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$mapValues$3(PairRDDFunctions.scala:752)\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions$$Lambda$4124/0x00000008415ea040.apply(Unknown Source)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1518)\n",
      "23/03/22 19:53:02 WARN TaskSetManager: Lost task 2.0 in stage 201.0 (TID 1540) (192.168.89.130 executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.base/java.util.Arrays.copyOf(Arrays.java:3865)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.mkArray(ArrayBuilder.scala:471)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.resize(ArrayBuilder.scala:475)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.ensureSize(ArrayBuilder.scala:487)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$eq(ArrayBuilder.scala:492)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$eq(ArrayBuilder.scala:462)\n",
      "\tat scala.collection.generic.Growable.$anonfun$$plus$plus$eq$1(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable$$Lambda$20/0x000000084009b840.apply(Unknown Source)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofFloat.foreach(ArrayOps.scala:270)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$plus$eq(ArrayBuilder.scala:505)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$plus$eq(ArrayBuilder.scala:462)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$UncompressedInBlockBuilder.add(ALS.scala:1426)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$makeBlocks$6(ALS.scala:1643)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$4147/0x00000008415d9040.apply(Unknown Source)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.util.collection.CompactBuffer$$anon$1.foreach(CompactBuffer.scala:115)\n",
      "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
      "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
      "\tat org.apache.spark.util.collection.CompactBuffer.foreach(CompactBuffer.scala:32)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$makeBlocks$5(ALS.scala:1642)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$4143/0x00000008415ec040.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$mapValues$3(PairRDDFunctions.scala:752)\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions$$Lambda$4124/0x00000008415ea040.apply(Unknown Source)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1518)\n",
      "\n",
      "23/03/22 19:53:02 ERROR TaskSetManager: Task 2 in stage 201.0 failed 1 times; aborting job\n",
      "23/03/22 19:53:03 WARN BlockManager: Block rdd_403_3 could not be removed as it was not found on disk or in memory\n",
      "23/03/22 19:53:03 WARN BlockManager: Block rdd_404_3 could not be removed as it was not found on disk or in memory\n",
      "23/03/22 19:53:03 ERROR Executor: Exception in task 3.0 in stage 201.0 (TID 1541)\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "23/03/22 19:53:03 ERROR SparkUncaughtExceptionHandler: [Container in shutdown] Uncaught exception in thread Thread[Executor task launch worker for task 3.0 in stage 201.0 (TID 1541),5,main]\n",
      "java.lang.OutOfMemoryError: Java heap space\n",
      "23/03/22 19:53:03 ERROR Instrumentation: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 201.0 failed 1 times, most recent failure: Lost task 2.0 in stage 201.0 (TID 1540) (192.168.89.130 executor driver): java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.base/java.util.Arrays.copyOf(Arrays.java:3865)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.mkArray(ArrayBuilder.scala:471)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.resize(ArrayBuilder.scala:475)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.ensureSize(ArrayBuilder.scala:487)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$eq(ArrayBuilder.scala:492)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$eq(ArrayBuilder.scala:462)\n",
      "\tat scala.collection.generic.Growable.$anonfun$$plus$plus$eq$1(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable$$Lambda$20/0x000000084009b840.apply(Unknown Source)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofFloat.foreach(ArrayOps.scala:270)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$plus$eq(ArrayBuilder.scala:505)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$plus$eq(ArrayBuilder.scala:462)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$UncompressedInBlockBuilder.add(ALS.scala:1426)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$makeBlocks$6(ALS.scala:1643)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$4147/0x00000008415d9040.apply(Unknown Source)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.util.collection.CompactBuffer$$anon$1.foreach(CompactBuffer.scala:115)\n",
      "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
      "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
      "\tat org.apache.spark.util.collection.CompactBuffer.foreach(CompactBuffer.scala:32)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$makeBlocks$5(ALS.scala:1642)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$4143/0x00000008415ec040.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$mapValues$3(PairRDDFunctions.scala:752)\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions$$Lambda$4124/0x00000008415ea040.apply(Unknown Source)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1518)\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2293)\n",
      "\tat org.apache.spark.rdd.RDD.count(RDD.scala:1274)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$.train(ALS.scala:973)\n",
      "\tat org.apache.spark.ml.recommendation.ALS.$anonfun$fit$1(ALS.scala:722)\n",
      "\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n",
      "\tat org.apache.spark.ml.recommendation.ALS.fit(ALS.scala:704)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.lang.OutOfMemoryError: Java heap space\n",
      "\tat java.base/java.util.Arrays.copyOf(Arrays.java:3865)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.mkArray(ArrayBuilder.scala:471)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.resize(ArrayBuilder.scala:475)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.ensureSize(ArrayBuilder.scala:487)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$eq(ArrayBuilder.scala:492)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$eq(ArrayBuilder.scala:462)\n",
      "\tat scala.collection.generic.Growable.$anonfun$$plus$plus$eq$1(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable$$Lambda$20/0x000000084009b840.apply(Unknown Source)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n",
      "\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n",
      "\tat scala.collection.mutable.ArrayOps$ofFloat.foreach(ArrayOps.scala:270)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$plus$eq(ArrayBuilder.scala:505)\n",
      "\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$plus$eq(ArrayBuilder.scala:462)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$UncompressedInBlockBuilder.add(ALS.scala:1426)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$makeBlocks$6(ALS.scala:1643)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$4147/0x00000008415d9040.apply(Unknown Source)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.util.collection.CompactBuffer$$anon$1.foreach(CompactBuffer.scala:115)\n",
      "\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n",
      "\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n",
      "\tat org.apache.spark.util.collection.CompactBuffer.foreach(CompactBuffer.scala:32)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$makeBlocks$5(ALS.scala:1642)\n",
      "\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$4143/0x00000008415ec040.apply(Unknown Source)\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$mapValues$3(PairRDDFunctions.scala:752)\n",
      "\tat org.apache.spark.rdd.PairRDDFunctions$$Lambda$4124/0x00000008415ea040.apply(Unknown Source)\n",
      "\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n",
      "\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n",
      "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1518)\n",
      "\n",
      "23/03/22 19:53:03 WARN BlockManager: Putting block rdd_403_4 failed due to exception org.apache.spark.TaskKilledException.\n",
      "23/03/22 19:53:03 WARN BlockManager: Block rdd_403_4 could not be removed as it was not found on disk or in memory\n",
      "23/03/22 19:53:03 WARN BlockManager: Putting block rdd_404_4 failed due to exception org.apache.spark.TaskKilledException.\n",
      "23/03/22 19:53:03 WARN BlockManager: Block rdd_404_4 could not be removed as it was not found on disk or in memory\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "('An error occurred while calling o381.fit.\\n', JavaObject id=o433)",
     "output_type": "error",
     "traceback": [
      "Traceback (most recent call last):",
      "  File \"python cell\", line 14, in <module>",
      "  File \"/opt/spark/python/pyspark/ml/base.py\", line 205, in fit\n    return self._fit(dataset)",
      "  File \"/opt/spark/python/pyspark/ml/wrapper.py\", line 383, in _fit\n    java_model = self._fit_java(dataset)",
      "  File \"/opt/spark/python/pyspark/ml/wrapper.py\", line 380, in _fit_java\n    return self._java_obj.fit(dataset._jdf)",
      "  File \"/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\", line 1321, in __call__\n    return_value = get_return_value(",
      "  File \"/opt/spark/python/pyspark/sql/utils.py\", line 190, in deco\n    return f(*a, **kw)",
      "  File \"/opt/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py\", line 326, in get_return_value\n    raise Py4JJavaError(",
      "Py4JJavaError: An error occurred while calling o381.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 201.0 failed 1 times, most recent failure: Lost task 2.0 in stage 201.0 (TID 1540) (192.168.89.130 executor driver): java.lang.OutOfMemoryError: Java heap space\n\tat java.base/java.util.Arrays.copyOf(Arrays.java:3865)\n\tat scala.collection.mutable.ArrayBuilder$ofFloat.mkArray(ArrayBuilder.scala:471)\n\tat scala.collection.mutable.ArrayBuilder$ofFloat.resize(ArrayBuilder.scala:475)\n\tat scala.collection.mutable.ArrayBuilder$ofFloat.ensureSize(ArrayBuilder.scala:487)\n\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$eq(ArrayBuilder.scala:492)\n\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$eq(ArrayBuilder.scala:462)\n\tat scala.collection.generic.Growable.$anonfun$$plus$plus$eq$1(Growable.scala:62)\n\tat scala.collection.generic.Growable$$Lambda$20/0x000000084009b840.apply(Unknown Source)\n\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofFloat.foreach(ArrayOps.scala:270)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$plus$eq(ArrayBuilder.scala:505)\n\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$plus$eq(ArrayBuilder.scala:462)\n\tat org.apache.spark.ml.recommendation.ALS$UncompressedInBlockBuilder.add(ALS.scala:1426)\n\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$makeBlocks$6(ALS.scala:1643)\n\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$4147/0x00000008415d9040.apply(Unknown Source)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.util.collection.CompactBuffer$$anon$1.foreach(CompactBuffer.scala:115)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat org.apache.spark.util.collection.CompactBuffer.foreach(CompactBuffer.scala:32)\n\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$makeBlocks$5(ALS.scala:1642)\n\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$4143/0x00000008415ec040.apply(Unknown Source)\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$mapValues$3(PairRDDFunctions.scala:752)\n\tat org.apache.spark.rdd.PairRDDFunctions$$Lambda$4124/0x00000008415ea040.apply(Unknown Source)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1518)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2228)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2249)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2268)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2293)\n\tat org.apache.spark.rdd.RDD.count(RDD.scala:1274)\n\tat org.apache.spark.ml.recommendation.ALS$.train(ALS.scala:973)\n\tat org.apache.spark.ml.recommendation.ALS.$anonfun$fit$1(ALS.scala:722)\n\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n\tat org.apache.spark.ml.recommendation.ALS.fit(ALS.scala:704)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.lang.OutOfMemoryError: Java heap space\n\tat java.base/java.util.Arrays.copyOf(Arrays.java:3865)\n\tat scala.collection.mutable.ArrayBuilder$ofFloat.mkArray(ArrayBuilder.scala:471)\n\tat scala.collection.mutable.ArrayBuilder$ofFloat.resize(ArrayBuilder.scala:475)\n\tat scala.collection.mutable.ArrayBuilder$ofFloat.ensureSize(ArrayBuilder.scala:487)\n\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$eq(ArrayBuilder.scala:492)\n\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$eq(ArrayBuilder.scala:462)\n\tat scala.collection.generic.Growable.$anonfun$$plus$plus$eq$1(Growable.scala:62)\n\tat scala.collection.generic.Growable$$Lambda$20/0x000000084009b840.apply(Unknown Source)\n\tat scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36)\n\tat scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofFloat.foreach(ArrayOps.scala:270)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$plus$eq(ArrayBuilder.scala:505)\n\tat scala.collection.mutable.ArrayBuilder$ofFloat.$plus$plus$eq(ArrayBuilder.scala:462)\n\tat org.apache.spark.ml.recommendation.ALS$UncompressedInBlockBuilder.add(ALS.scala:1426)\n\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$makeBlocks$6(ALS.scala:1643)\n\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$4147/0x00000008415d9040.apply(Unknown Source)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.util.collection.CompactBuffer$$anon$1.foreach(CompactBuffer.scala:115)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat org.apache.spark.util.collection.CompactBuffer.foreach(CompactBuffer.scala:32)\n\tat org.apache.spark.ml.recommendation.ALS$.$anonfun$makeBlocks$5(ALS.scala:1642)\n\tat org.apache.spark.ml.recommendation.ALS$$$Lambda$4143/0x00000008415ec040.apply(Unknown Source)\n\tat org.apache.spark.rdd.PairRDDFunctions.$anonfun$mapValues$3(PairRDDFunctions.scala:752)\n\tat org.apache.spark.rdd.PairRDDFunctions$$Lambda$4124/0x00000008415ea040.apply(Unknown Source)\n\tat scala.collection.Iterator$$anon$10.next(Iterator.scala:461)\n\tat org.apache.spark.storage.memory.MemoryStore.putIterator(MemoryStore.scala:224)\n\tat org.apache.spark.storage.memory.MemoryStore.putIteratorAsValues(MemoryStore.scala:302)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1518)\n"
     ]
    }
   ],
   "source": [
    "# Importando as bibliotecas necessÃ¡rias\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Criando um vetor com os atributos que serÃ£o usados para fazer as recomendaÃ§Ãµes\n",
    "vectorAssembler = VectorAssembler(inputCols=[\"srch_children_cnt\", \"is_mobile\", \"is_booking\", \"is_package\", \"user_location_country\"], outputCol=\"features\")\n",
    "df_hotels = vectorAssembler.transform(df_hotels)\n",
    "\n",
    "# Separando os dados em conjuntos de treinamento e teste\n",
    "(training, test) = df_hotels.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Configurando o modelo ALS (Alternating Least Squares) para fazer as recomendaÃ§Ãµes\n",
    "als = ALS(userCol=\"user_id\", itemCol=\"hotel_cluster\", ratingCol=\"is_booking\", coldStartStrategy=\"drop\")\n",
    "model = als.fit(training)\n",
    "\n",
    "# Fazendo as recomendaÃ§Ãµes para cada usuÃ¡rio com base em seus histÃ³ricos de reservas e outros atributos\n",
    "recommendations = model.recommendForAllUsers(10)\n",
    "\n",
    "# Mostrando as recomendaÃ§Ãµes para um usuÃ¡rio especÃ­fico\n",
    "recommendations.filter(recommendations.user_id == 1234).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf0fb95-53a5-4866-8b3c-a51fffc60ce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
