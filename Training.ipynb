{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2693084-6718-4221-8044-28587d7cff80",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9138ddb-88fd-4cf2-97f1-1750ecff2d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "    # build our own SparkSession\n",
    "spark = (SparkSession\n",
    "        .builder\n",
    "        .appName(\"BigData\")\n",
    "        .config(\"spark.sql.shuffle.partitions\",6)\n",
    "        .config(\"spark.sql.repl.eagereval.enabled\",True)\n",
    "        .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec88f023-703d-472f-9521-92a043c65f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotels = spark.read.parquet('small-hotels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bcaf2f0-bf55-4199-9e52-a38d5e102bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from ydata_profiling import ProfileReport\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2227b75f-0165-4383-aa35-bac653d47e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------------\n",
      " date_time                | 2014-09-02 01:05:54 \n",
      " site_name                | 2                   \n",
      " posa_continent           | 3                   \n",
      " user_location_country    | 75                  \n",
      " user_location_region     | 144                 \n",
      " user_location_city       | 52467               \n",
      " user_id                  | 1145960             \n",
      " is_mobile                | 0                   \n",
      " is_package               | 0                   \n",
      " channel                  | 9                   \n",
      " srch_ci                  | 2014-09-03 00:00:00 \n",
      " srch_co                  | 2014-09-08 00:00:00 \n",
      " srch_adults_cnt          | 2                   \n",
      " srch_children_cnt        | 0                   \n",
      " srch_rm_cnt              | 1                   \n",
      " srch_destination_id      | 46375               \n",
      " srch_destination_type_id | 1                   \n",
      " is_booking               | 0                   \n",
      " cnt                      | 1                   \n",
      " hotel_continent          | 5                   \n",
      " hotel_country            | 147                 \n",
      " hotel_market             | 143                 \n",
      " hotel_cluster            | 30                  \n",
      " Id_hotel                 | 301431475           \n",
      " num_nights               | 5                   \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_hotels.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48507543-1272-4fde-aadf-82ec55426c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotel = df_hotels.select(\"num_nights\", \"cnt\", \"srch_rm_cnt\", \"srch_adults_cnt\", \"srch_children_cnt\", \"channel\", \"is_mobile\", \"is_booking\", \"is_package\", \"user_location_country\", \"user_location_city\", \"user_location_region\", \"Id_hotel\", \"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b1dbe43-8ecd-4892-a400-2d8c62d41607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import avg, when, col\n",
    "\n",
    "# Calcular a média de \"is_booking\" quando igual a 1\n",
    "booking_avg = df_hotels.select(avg(when(col(\"is_booking\") == 1, 1))).collect()[0][0]\n",
    "\n",
    "# Calcular a porcentagem de \"is_booking\" igual a 1\n",
    "booking_percentage = df_hotels.filter(col(\"is_booking\") == 1).count() / df_hotels.count()\n",
    "\n",
    "# Adicionar a porcentagem à coluna \"is_booking\"\n",
    "df_hotels = df_hotels.withColumn(\"is_booking\", col(\"is_booking\") + booking_percentage * booking_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703d3878-0795-4697-8269-977f55e06521",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1530a366-aa0c-4992-92c0-69dcd06b308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----------------+------------------+--------------------+--------------------+-----------------+-------+---------------+\n",
      "|user_location_country| country_encoded|user_location_city|        city_encoded|user_location_region|   region_encoded|channel|channel_encoded|\n",
      "+---------------------+----------------+------------------+--------------------+--------------------+-----------------+-------+---------------+\n",
      "|                   75|(212,[58],[1.0])|             52467| (17894,[287],[1.0])|                 144|(857,[156],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                  218|(212,[40],[1.0])|             39100| (17894,[217],[1.0])|                  17|(857,[127],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                  218|(212,[40],[1.0])|             39100| (17894,[217],[1.0])|                  17|(857,[127],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                   66| (212,[0],[1.0])|              4948| (17894,[150],[1.0])|                 220|  (857,[4],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                   66| (212,[0],[1.0])|              4948| (17894,[150],[1.0])|                 220|  (857,[4],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                   66| (212,[0],[1.0])|              4948| (17894,[150],[1.0])|                 220|  (857,[4],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                   66| (212,[0],[1.0])|              4948| (17894,[150],[1.0])|                 220|  (857,[4],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                  205| (212,[1],[1.0])|             25315|   (17894,[3],[1.0])|                 354|  (857,[2],[1.0])|      2| (10,[3],[1.0])|\n",
      "|                   66| (212,[0],[1.0])|             24503|(17894,[1137],[1.0])|                 258|  (857,[9],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                   71|(212,[31],[1.0])|             22827|(17894,[5706],[1.0])|                   0| (857,[16],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                   66| (212,[0],[1.0])|             21309|(17894,[4083],[1.0])|                 337| (857,[10],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                  205| (212,[1],[1.0])|             40095| (17894,[198],[1.0])|                 155|  (857,[7],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                   66| (212,[0],[1.0])|              2086|   (17894,[8],[1.0])|                 220|  (857,[4],[1.0])|      7| (10,[7],[1.0])|\n",
      "|                   62|(212,[24],[1.0])|              7652|(17894,[17571],[1...|                  24|(857,[240],[1.0])|      1| (10,[2],[1.0])|\n",
      "|                   66| (212,[0],[1.0])|             29563|(17894,[1084],[1.0])|                 442|  (857,[3],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                   66| (212,[0],[1.0])|              2822| (17894,[581],[1.0])|                 442|  (857,[3],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                   66| (212,[0],[1.0])|             21621| (17894,[858],[1.0])|                 442|  (857,[3],[1.0])|      1| (10,[2],[1.0])|\n",
      "|                  215| (212,[7],[1.0])|             13087| (17894,[199],[1.0])|                 817| (857,[94],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                   66| (212,[0],[1.0])|             32759| (17894,[332],[1.0])|                 314| (857,[26],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                  133| (212,[8],[1.0])|             18770|(17894,[12294],[1...|                  31|(857,[117],[1.0])|      9| (10,[0],[1.0])|\n",
      "+---------------------+----------------+------------------+--------------------+--------------------+-----------------+-------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "\n",
    "# Creating StringIndexer objects for each categorical variable\n",
    "indexer_country = StringIndexer(inputCol=\"user_location_country\", outputCol=\"country_index\")\n",
    "indexer_city = StringIndexer(inputCol=\"user_location_city\", outputCol=\"city_index\")\n",
    "indexer_region = StringIndexer(inputCol=\"user_location_region\", outputCol=\"region_index\")\n",
    "indexer_channel = StringIndexer(inputCol=\"channel\", outputCol=\"channel_index\")\n",
    "\n",
    "# Fitting the StringIndexer objects on the data\n",
    "indexer_model_country = indexer_country.fit(df_hotel)\n",
    "indexer_model_city = indexer_city.fit(df_hotel)\n",
    "indexer_model_region = indexer_region.fit(df_hotel)\n",
    "indexer_model_channel = indexer_channel.fit(df_hotel)\n",
    "\n",
    "# Transforming the data using the StringIndexer objects\n",
    "df_hotel_indexed = indexer_model_country.transform(df_hotel)\n",
    "df_hotel_indexed = indexer_model_city.transform(df_hotel_indexed)\n",
    "df_hotel_indexed = indexer_model_region.transform(df_hotel_indexed)\n",
    "df_hotel_indexed = indexer_model_channel.transform(df_hotel_indexed)\n",
    "\n",
    "# Creating OneHotEncoder objects for each categorical variable\n",
    "encoder_country = OneHotEncoder(inputCol=\"country_index\", outputCol=\"country_encoded\")\n",
    "encoder_city = OneHotEncoder(inputCol=\"city_index\", outputCol=\"city_encoded\")\n",
    "encoder_region = OneHotEncoder(inputCol=\"region_index\", outputCol=\"region_encoded\")\n",
    "encoder_channel = OneHotEncoder(inputCol=\"channel_index\", outputCol=\"channel_encoded\")\n",
    "\n",
    "# Fitting the OneHotEncoder objects on the data\n",
    "encoder_model_country = encoder_country.fit(df_hotel_indexed)\n",
    "encoder_model_city = encoder_city.fit(df_hotel_indexed)\n",
    "encoder_model_region = encoder_region.fit(df_hotel_indexed)\n",
    "encoder_model_channel = encoder_channel.fit(df_hotel_indexed)\n",
    "\n",
    "# Transforming the data using the OneHotEncoder objects\n",
    "df_hotel_encoded = encoder_model_country.transform(df_hotel_indexed)\n",
    "df_hotel_encoded = encoder_model_city.transform(df_hotel_encoded)\n",
    "df_hotel_encoded = encoder_model_region.transform(df_hotel_encoded)\n",
    "df_hotel_encoded = encoder_model_channel.transform(df_hotel_encoded)\n",
    "\n",
    "# Displaying the encoded data\n",
    "df_hotel_encoded.select(\"user_location_country\", \"country_encoded\", \"user_location_city\", \"city_encoded\", \"user_location_region\", \"region_encoded\", \"channel\", \"channel_encoded\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15e7cdd-3544-4996-bd4e-7564e409c3a2",
   "metadata": {},
   "source": [
    "# Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d860d888-ae3a-4f77-9967-9de7f3af5a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            features|     scaled_features|\n",
      "+--------------------+--------------------+\n",
      "|[5.0,1.0,1.0,2.0,...|[1.61125150707184...|\n",
      "|[3.0,3.0,1.0,2.0,...|[0.96675090424310...|\n",
      "|[5.0,1.0,1.0,2.0,...|[1.61125150707184...|\n",
      "|[5.0,1.0,1.0,1.0,...|[1.61125150707184...|\n",
      "|[1.0,1.0,1.0,2.0,...|[0.32225030141436...|\n",
      "|[2.0,1.0,1.0,2.0,...|[0.64450060282873...|\n",
      "|[2.0,1.0,1.0,2.0,...|[0.64450060282873...|\n",
      "|[3.0,1.0,1.0,4.0,...|[0.96675090424310...|\n",
      "|[2.0,2.0,2.0,2.0,...|[0.64450060282873...|\n",
      "|[1.0,1.0,1.0,2.0,...|[0.32225030141436...|\n",
      "|[2.0,2.0,1.0,1.0,...|[0.64450060282873...|\n",
      "|[3.0,1.0,1.0,2.0,...|[0.96675090424310...|\n",
      "|[3.0,1.0,1.0,2.0,...|[0.96675090424310...|\n",
      "|[3.0,4.0,1.0,2.0,...|[0.96675090424310...|\n",
      "|[1.0,1.0,1.0,2.0,...|[0.32225030141436...|\n",
      "|[2.0,2.0,2.0,2.0,...|[0.64450060282873...|\n",
      "|[9.0,3.0,2.0,3.0,...|[2.90025271272932...|\n",
      "|[2.0,2.0,1.0,1.0,...|[0.64450060282873...|\n",
      "|[5.0,1.0,1.0,4.0,...|[1.61125150707184...|\n",
      "|[2.0,1.0,1.0,2.0,...|[0.64450060282873...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "\n",
    "# Creating a VectorAssembler to assemble the features into a single vector\n",
    "vectorAssembler = VectorAssembler(inputCols=[\"num_nights\", \"cnt\", \"srch_rm_cnt\", \"srch_adults_cnt\", \"srch_children_cnt\"], outputCol=\"features\")\n",
    "df_hotel = vectorAssembler.transform(df_hotel)\n",
    "\n",
    "# Creating a StandardScaler object to scale the features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "\n",
    "# Fitting the StandardScaler on the data\n",
    "scaler_model = scaler.fit(df_hotel)\n",
    "\n",
    "# Transforming the data using the StandardScaler\n",
    "df_hotel_scaled = scaler_model.transform(df_hotel)\n",
    "\n",
    "# Displaying the scaled data\n",
    "df_hotel_scaled.select(\"features\", \"scaled_features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5f957b-b618-4564-8be1-b8873902aa22",
   "metadata": {},
   "source": [
    "## Doing Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b410a8d8-5c6b-476c-a64e-da1cbcda2387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|  assembled_features|     scaled_features|\n",
      "+--------------------+--------------------+\n",
      "|[5.0,1.0,1.0,2.0,...|[1.61125150707184...|\n",
      "|[3.0,3.0,1.0,2.0,...|[0.96675090424310...|\n",
      "|[5.0,1.0,1.0,2.0,...|[1.61125150707184...|\n",
      "|[5.0,1.0,1.0,1.0,...|[1.61125150707184...|\n",
      "|[1.0,1.0,1.0,2.0,...|[0.32225030141436...|\n",
      "|[2.0,1.0,1.0,2.0,...|[0.64450060282873...|\n",
      "|[2.0,1.0,1.0,2.0,...|[0.64450060282873...|\n",
      "|[3.0,1.0,1.0,4.0,...|[0.96675090424310...|\n",
      "|[2.0,2.0,2.0,2.0,...|[0.64450060282873...|\n",
      "|[1.0,1.0,1.0,2.0,...|[0.32225030141436...|\n",
      "|[2.0,2.0,1.0,1.0,...|[0.64450060282873...|\n",
      "|[3.0,1.0,1.0,2.0,...|[0.96675090424310...|\n",
      "|[3.0,1.0,1.0,2.0,...|[0.96675090424310...|\n",
      "|[3.0,4.0,1.0,2.0,...|[0.96675090424310...|\n",
      "|[1.0,1.0,1.0,2.0,...|[0.32225030141436...|\n",
      "|[2.0,2.0,2.0,2.0,...|[0.64450060282873...|\n",
      "|[9.0,3.0,2.0,3.0,...|[2.90025271272932...|\n",
      "|[2.0,2.0,1.0,1.0,...|[0.64450060282873...|\n",
      "|[5.0,1.0,1.0,4.0,...|[1.61125150707184...|\n",
      "|[2.0,1.0,1.0,2.0,...|[0.64450060282873...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "\n",
    "# Creating StringIndexer objects for each categorical variable\n",
    "indexer_country = StringIndexer(inputCol=\"user_location_country\", outputCol=\"country_index\")\n",
    "indexer_city = StringIndexer(inputCol=\"user_location_city\", outputCol=\"city_index\")\n",
    "indexer_region = StringIndexer(inputCol=\"user_location_region\", outputCol=\"region_index\")\n",
    "indexer_channel = StringIndexer(inputCol=\"channel\", outputCol=\"channel_index\")\n",
    "\n",
    "# Creating OneHotEncoder objects for each categorical variable\n",
    "encoder_country = OneHotEncoder(inputCol=\"country_index\", outputCol=\"country_encoded\")\n",
    "encoder_city = OneHotEncoder(inputCol=\"city_index\", outputCol=\"city_encoded\")\n",
    "encoder_region = OneHotEncoder(inputCol=\"region_index\", outputCol=\"region_encoded\")\n",
    "encoder_channel = OneHotEncoder(inputCol=\"channel_index\", outputCol=\"channel_encoded\")\n",
    "\n",
    "# Creating a VectorAssembler to assemble the features into a single vector\n",
    "vectorAssembler = VectorAssembler(inputCols=[\"num_nights\", \"cnt\", \"srch_rm_cnt\", \"srch_adults_cnt\", \"srch_children_cnt\"], outputCol=\"assembled_features\")\n",
    "df_hotel_assembled = vectorAssembler.transform(df_hotel_encoded)\n",
    "\n",
    "# Creating a StandardScaler object to scale the features\n",
    "scaler = StandardScaler(inputCol=\"assembled_features\", outputCol=\"scaled_features\")\n",
    "\n",
    "# Fitting the StandardScaler on the data\n",
    "scaler_model = scaler.fit(df_hotel_assembled)\n",
    "\n",
    "# Transforming the data using the StandardScaler\n",
    "df_hotel_scaled = scaler_model.transform(df_hotel_assembled)\n",
    "\n",
    "# Displaying the scaled data\n",
    "df_hotel_scaled.select(\"assembled_features\", \"scaled_features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c383b0-bac2-403f-b7bf-e53742631b90",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1674cc59-83ba-4d5c-ae85-1219712a8d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Criando um vetor com os atributos que serão usados para fazer as recomendações\n",
    "vectorAssembler = VectorAssembler(inputCols=[\"num_nights\", \"cnt\", \"srch_rm_cnt\", \"srch_adults_cnt\", \"srch_children_cnt\", \"channel\", \"is_mobile\", \"is_booking\", \"is_package\", \"user_location_country\", \"user_location_city\", \"user_location_region\", \"scaled_features\"], outputCol=\"features\")\n",
    "df_hotels = vectorAssembler.transform(df_hotel_scaled)\n",
    "\n",
    "# Separando os dados em conjuntos de treinamento e teste\n",
    "#(training, test) = df_hotels.randomSplit([0.8, 0.2])\n",
    "\n",
    "training = df_hotels.sampleBy(\"is_booking\", fractions={0: 0.8, 1: 0.8}, seed=42)\n",
    "test = df_hotels.subtract(training)\n",
    "\n",
    "\n",
    "# Configurando o modelo ALS (Alternating Least Squares) para fazer as recomendações\n",
    "als = ALS(userCol=\"user_id\", itemCol=\"Id_hotel\", ratingCol=\"is_booking\", coldStartStrategy=\"drop\")\n",
    "model = als.fit(training)\n",
    "\n",
    "#recommendations = model.recommendForAllUsers(10)\n",
    "\n",
    "user_subset = df_hotels.filter(col(\"is_booking\") > 0).select('user_id')\n",
    "recommendations = model.recommendForUserSubset(user_subset, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "432972e2-7433-45f8-bd77-bc1d83752d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/08 18:05:27 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "-RECORD 0-------------------------------------\n",
      " num_nights            | 5                    \n",
      " cnt                   | 1                    \n",
      " srch_rm_cnt           | 1                    \n",
      " srch_adults_cnt       | 2                    \n",
      " srch_children_cnt     | 0                    \n",
      " channel               | 9                    \n",
      " is_mobile             | 0                    \n",
      " is_booking            | 0                    \n",
      " is_package            | 0                    \n",
      " user_location_country | 75                   \n",
      " user_location_city    | 52467                \n",
      " user_location_region  | 144                  \n",
      " Id_hotel              | 301431475            \n",
      " user_id               | 1145960              \n",
      " country_index         | 58.0                 \n",
      " city_index            | 287.0                \n",
      " region_index          | 156.0                \n",
      " channel_index         | 0.0                  \n",
      " country_encoded       | (212,[58],[1.0])     \n",
      " city_encoded          | (17894,[287],[1.0])  \n",
      " region_encoded        | (857,[156],[1.0])    \n",
      " channel_encoded       | (10,[0],[1.0])       \n",
      " assembled_features    | [5.0,1.0,1.0,2.0,... \n",
      " scaled_features       | [1.61125150707184... \n",
      " features              | [5.0,1.0,1.0,2.0,... \n",
      "-RECORD 1-------------------------------------\n",
      " num_nights            | 3                    \n",
      " cnt                   | 3                    \n",
      " srch_rm_cnt           | 1                    \n",
      " srch_adults_cnt       | 2                    \n",
      " srch_children_cnt     | 1                    \n",
      " channel               | 9                    \n",
      " is_mobile             | 0                    \n",
      " is_booking            | 0                    \n",
      " is_package            | 0                    \n",
      " user_location_country | 218                  \n",
      " user_location_city    | 39100                \n",
      " user_location_region  | 17                   \n",
      " Id_hotel              | 6212684              \n",
      " user_id               | 1145987              \n",
      " country_index         | 40.0                 \n",
      " city_index            | 217.0                \n",
      " region_index          | 127.0                \n",
      " channel_index         | 0.0                  \n",
      " country_encoded       | (212,[40],[1.0])     \n",
      " city_encoded          | (17894,[217],[1.0])  \n",
      " region_encoded        | (857,[127],[1.0])    \n",
      " channel_encoded       | (10,[0],[1.0])       \n",
      " assembled_features    | [3.0,3.0,1.0,2.0,... \n",
      " scaled_features       | [0.96675090424310... \n",
      " features              | [3.0,3.0,1.0,2.0,... \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_hotels.show(2, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1f9b418-571d-4e8b-bad2-d0af33dd4073",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 658:==================================================>   (94 + 6) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+\n",
      "|user_id|recommendations|\n",
      "+-------+---------------+\n",
      "+-------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 658:====================================================> (98 + 2) / 100]\r"
     ]
    }
   ],
   "source": [
    "recommendations.filter(recommendations.user_id == 336709).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee91d409-3da7-420b-bef5-30e4b26a86a6",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f4c6b0-adf1-4c84-a1ad-94399aa8385a",
   "metadata": {},
   "source": [
    "# Interpretando Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d94071-35a7-4bbe-a3dd-fba24558d7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b36bcc08-57ea-4561-8171-8b71b29eb678",
   "metadata": {},
   "source": [
    "# Using the model with new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3665507a-7d49-4395-9616-a6d143204bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+\n",
      "|user_id|recommendations|\n",
      "+-------+---------------+\n",
      "+-------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "# criar um novo DataFrame para um novo usuário\n",
    "new_user = Row(user_id=999, num_nights=3, cnt=2, srch_rm_cnt=1, srch_adults_cnt=2, srch_children_cnt=0,\n",
    "               channel=1, is_mobile=0, is_booking=0, is_package=1, user_location_country=50, user_location_city=1234,\n",
    "               user_location_region=123)\n",
    "\n",
    "new_user_df = spark.createDataFrame([new_user])\n",
    "\n",
    "# gerar recomendações para o novo usuário\n",
    "new_user_recs = model.recommendForUserSubset(new_user_df, 10)\n",
    "new_user_recs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c773e41d-c512-45b0-a460-85d3691b54be",
   "metadata": {},
   "source": [
    "# Validar o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b95f7d-419d-4d65-8ca4-a33c371a6839",
   "metadata": {},
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "706f7d57-38fb-447c-8f1d-d7d090691f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/08 17:57:51 WARN DAGScheduler: Broadcasting large task binary with size 1535.6 KiB\n",
      "23/04/08 17:57:51 WARN DAGScheduler: Broadcasting large task binary with size 1557.0 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 335:===============================>                         (5 + 4) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/08 17:57:53 WARN DAGScheduler: Broadcasting large task binary with size 1730.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 387:=========>                                               (1 + 5) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/08 17:57:56 WARN DAGScheduler: Broadcasting large task binary with size 1606.5 KiB\n",
      "23/04/08 17:57:57 WARN DAGScheduler: Broadcasting large task binary with size 1671.1 KiB\n",
      "Accuracy: 85.21%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "predictions = model.transform(test)\n",
    "predictions = predictions.withColumn(\"prediction\", col(\"prediction\").cast(\"double\"))\n",
    "# Avalia as previsões do modelo nos dados de teste\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"is_booking\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy: {:.2%}\".format(accuracy))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"is_booking\", metricName=\"weightedPrecision\")\n",
    "precision = evaluator.evaluate(predictions)\n",
    "print(\"Precision: {:.2%}\".format(precision))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"is_booking\", metricName=\"weightedRecall\")\n",
    "recall = evaluator.evaluate(predictions)\n",
    "print(\"Recall: {:.2%}\".format(recall))\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"is_booking\", metricName=\"f1\")\n",
    "f1 = evaluator.evaluate(predictions)\n",
    "print(\"F1: {:.2%}\".format(f1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b01b84-27f0-4eb4-a37e-55349a050912",
   "metadata": {},
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608e54fb-d7cc-443d-b9d3-78c07c1f7848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pyspark.serializers import PickleSerializer\n",
    "\n",
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc38b981-0457-4b08-8581-a4b66dc2a934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:28 WARN DAGScheduler: Broadcasting large task binary with size 1586.6 KiB\n",
      "23/04/07 12:35:28 WARN DAGScheduler: Broadcasting large task binary with size 1608.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:30 WARN DAGScheduler: Broadcasting large task binary with size 1781.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 784:============================>                            (3 + 3) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:32 WARN DAGScheduler: Broadcasting large task binary with size 1657.6 KiB\n",
      "23/04/07 12:35:32 WARN DAGScheduler: Broadcasting large task binary with size 1722.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:32 WARN DAGScheduler: Broadcasting large task binary with size 1586.6 KiB\n",
      "23/04/07 12:35:32 WARN DAGScheduler: Broadcasting large task binary with size 1608.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:33 WARN DAGScheduler: Broadcasting large task binary with size 1781.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 872:>                                                        (0 + 6) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:35 WARN DAGScheduler: Broadcasting large task binary with size 1657.6 KiB\n",
      "23/04/07 12:35:35 WARN DAGScheduler: Broadcasting large task binary with size 1722.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:35 WARN DAGScheduler: Broadcasting large task binary with size 1586.6 KiB\n",
      "23/04/07 12:35:35 WARN DAGScheduler: Broadcasting large task binary with size 1608.1 KiB\n",
      "23/04/07 12:35:36 WARN DAGScheduler: Broadcasting large task binary with size 1781.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 960:>                                                        (0 + 6) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:37 WARN DAGScheduler: Broadcasting large task binary with size 1657.6 KiB\n",
      "23/04/07 12:35:38 WARN DAGScheduler: Broadcasting large task binary with size 1722.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:38 WARN DAGScheduler: Broadcasting large task binary with size 1586.6 KiB\n",
      "23/04/07 12:35:38 WARN DAGScheduler: Broadcasting large task binary with size 1608.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:39 WARN DAGScheduler: Broadcasting large task binary with size 1781.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1048:>                                                       (0 + 6) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:40 WARN DAGScheduler: Broadcasting large task binary with size 1657.6 KiB\n",
      "23/04/07 12:35:40 WARN DAGScheduler: Broadcasting large task binary with size 1722.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Avalia as previsões do modelo nos dados de teste\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"is_booking\")\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "f1_score = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d4a7f5a3-e426-49a4-9019-d503f3ad2dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8161745233050848\n",
      "Precision:  0.85947772305961\n",
      "Recall:  0.8161745233050848\n",
      "f1_score 0.8372665896893304\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score\", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63caf86-795c-4f77-a744-b85d46886c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20710791-ecfd-43df-be9e-46eb641fe726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a147efc-e5f0-437f-b7a1-3ad47ea1de68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bf7f30-0af0-46fc-bea1-1a17c5cf5612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e1f056-0ca7-494a-91c2-4c18807132ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c9cc7d-010f-4003-963a-fb72df6e606c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68c474e6-bb76-43aa-a080-b40d47dfa05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "\n",
    "# Criando um vetor com os atributos que serão usados para fazer as recomendações\n",
    "vectorAssembler = VectorAssembler(inputCols=[\"num_nights\", \"cnt\", \"srch_rm_cnt\", \"srch_adults_cnt\", \"srch_children_cnt\", \"channel\",\"is_mobile\", \"is_booking\", \"is_package\", \"user_location_country\", \"user_location_city\", \"user_location_region\"], outputCol=\"features\")\n",
    "df_hotels = vectorAssembler.transform(df_hotel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb6f8fb5-d362-4f69-a3d6-5236dc89a77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 11:11:54 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/04/07 11:11:54 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "23/04/07 11:11:54 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    }
   ],
   "source": [
    "# Separando os dados em conjuntos de treinamento e teste\n",
    "(training, test) = df_hotels.randomSplit([0.8, 0.2])\n",
    "\n",
    "\n",
    "# Configurando o modelo ALS (Alternating Least Squares) para fazer as recomendações\n",
    "als = ALS(userCol=\"user_id\", itemCol=\"Id_hotel\", ratingCol=\"is_booking\", coldStartStrategy=\"drop\")\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e808b9aa-2a43-4928-b294-140e13593657",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = model.recommendForAllUsers(10) #Não usem esta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a206fe5-e22b-4ee2-ae59-0c10ca11a2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 105:==============================>                      (58 + 10) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------------------------------------------------------------------------------------+\n",
      "|user_id|recommendations                                                                                                 |\n",
      "+-------+----------------------------------------------------------------------------------------------------------------+\n",
      "|336350 |[{-260, 0.0}, {0, 0.0}, {10, 0.0}, {20, 0.0}, {30, 0.0}, {40, 0.0}, {50, 0.0}, {60, 0.0}, {-309, 0.0}, {1, 0.0}]|\n",
      "+-------+----------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "recommendations.filter(recommendations.user_id == 336350).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6523e234-26c3-4524-b3fa-1a6c2f652c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------\n",
      " num_nights            | 5                    \n",
      " cnt                   | 2                    \n",
      " srch_rm_cnt           | 2                    \n",
      " srch_adults_cnt       | 2                    \n",
      " srch_children_cnt     | 4                    \n",
      " channel               | 9                    \n",
      " is_mobile             | 0                    \n",
      " is_booking            | 0                    \n",
      " is_package            | 0                    \n",
      " user_location_country | 19                   \n",
      " user_location_city    | 1454                 \n",
      " Id_hotel              | 5                    \n",
      " user_location_region  | 58                   \n",
      " user_id               | 336350               \n",
      " features              | [5.0,2.0,2.0,2.0,... \n",
      "-RECORD 1-------------------------------------\n",
      " num_nights            | 8                    \n",
      " cnt                   | 1                    \n",
      " srch_rm_cnt           | 1                    \n",
      " srch_adults_cnt       | 2                    \n",
      " srch_children_cnt     | 0                    \n",
      " channel               | 9                    \n",
      " is_mobile             | 0                    \n",
      " is_booking            | 0                    \n",
      " is_package            | 1                    \n",
      " user_location_country | 66                   \n",
      " user_location_city    | 38899                \n",
      " Id_hotel              | 8                    \n",
      " user_location_region  | 174                  \n",
      " user_id               | 336599               \n",
      " features              | [8.0,1.0,1.0,2.0,... \n",
      "-RECORD 2-------------------------------------\n",
      " num_nights            | 2                    \n",
      " cnt                   | 1                    \n",
      " srch_rm_cnt           | 1                    \n",
      " srch_adults_cnt       | 2                    \n",
      " srch_children_cnt     | 0                    \n",
      " channel               | 0                    \n",
      " is_mobile             | 0                    \n",
      " is_booking            | 0                    \n",
      " is_package            | 0                    \n",
      " user_location_country | 66                   \n",
      " user_location_city    | 31674                \n",
      " Id_hotel              | 2                    \n",
      " user_location_region  | 442                  \n",
      " user_id               | 336709               \n",
      " features              | [2.0,1.0,1.0,2.0,... \n",
      "-RECORD 3-------------------------------------\n",
      " num_nights            | 4                    \n",
      " cnt                   | 1                    \n",
      " srch_rm_cnt           | 1                    \n",
      " srch_adults_cnt       | 2                    \n",
      " srch_children_cnt     | 0                    \n",
      " channel               | 9                    \n",
      " is_mobile             | 0                    \n",
      " is_booking            | 0                    \n",
      " is_package            | 1                    \n",
      " user_location_country | 66                   \n",
      " user_location_city    | 35390                \n",
      " Id_hotel              | 4                    \n",
      " user_location_region  | 442                  \n",
      " user_id               | 336709               \n",
      " features              | [4.0,1.0,1.0,2.0,... \n",
      "-RECORD 4-------------------------------------\n",
      " num_nights            | 1                    \n",
      " cnt                   | 1                    \n",
      " srch_rm_cnt           | 1                    \n",
      " srch_adults_cnt       | 2                    \n",
      " srch_children_cnt     | 0                    \n",
      " channel               | 9                    \n",
      " is_mobile             | 0                    \n",
      " is_booking            | 0                    \n",
      " is_package            | 0                    \n",
      " user_location_country | 66                   \n",
      " user_location_city    | 9890                 \n",
      " Id_hotel              | 1                    \n",
      " user_location_region  | 174                  \n",
      " user_id               | 336885               \n",
      " features              | [1.0,1.0,1.0,2.0,... \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_hotels.show(5,vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a51b54-778c-491c-8992-fc53c945af51",
   "metadata": {},
   "source": [
    "- Como Normailzar os Dados\n",
    "- Como validar o modelo, calcular performance\n",
    "- Como ter a lista de hoteis recomendados\n",
    "- Tirar cnt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50720d6-8397-46c0-b1f4-faa78f4dd2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
