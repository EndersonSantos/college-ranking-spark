{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2693084-6718-4221-8044-28587d7cff80",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9138ddb-88fd-4cf2-97f1-1750ecff2d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 11:01:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/04/07 11:01:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/04/07 11:01:36 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "    # build our own SparkSession\n",
    "spark = (SparkSession\n",
    "        .builder\n",
    "        .appName(\"BigData\")\n",
    "        .config(\"spark.sql.shuffle.partitions\",6)\n",
    "        .config(\"spark.sql.repl.eagereval.enabled\",True)\n",
    "        .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec88f023-703d-472f-9521-92a043c65f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotels = spark.read.parquet('small-hotels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bcaf2f0-bf55-4199-9e52-a38d5e102bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# from ydata_profiling import ProfileReport\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2227b75f-0165-4383-aa35-bac653d47e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0---------------------------------------\n",
      " date_time                | 2014-07-14 17:37:39 \n",
      " site_name                | 2                   \n",
      " posa_continent           | 3                   \n",
      " user_location_country    | 19                  \n",
      " user_location_region     | 58                  \n",
      " user_location_city       | 1454                \n",
      " user_id                  | 336350              \n",
      " is_mobile                | 0                   \n",
      " is_package               | 0                   \n",
      " channel                  | 9                   \n",
      " srch_ci                  | 2014-08-11 00:00:00 \n",
      " srch_co                  | 2014-08-16 00:00:00 \n",
      " srch_adults_cnt          | 2                   \n",
      " srch_children_cnt        | 4                   \n",
      " srch_rm_cnt              | 2                   \n",
      " srch_destination_id      | 8279                \n",
      " srch_destination_type_id | 1                   \n",
      " is_booking               | 0                   \n",
      " cnt                      | 2                   \n",
      " hotel_continent          | 2                   \n",
      " hotel_country            | 50                  \n",
      " hotel_market             | 1230                \n",
      " hotel_cluster            | 70                  \n",
      " Id_hotel                 | 5                   \n",
      " num_nights               | 5                   \n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_hotels.show(1, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "48507543-1272-4fde-aadf-82ec55426c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hotel = df_hotels.select(\"num_nights\", \"cnt\", \"srch_rm_cnt\", \"srch_adults_cnt\", \"srch_children_cnt\", \"channel\", \"is_mobile\", \"is_booking\", \"is_package\", \"user_location_country\", \"user_location_city\", \"user_location_region\", \"Id_hotel\", \"user_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703d3878-0795-4697-8269-977f55e06521",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1530a366-aa0c-4992-92c0-69dcd06b308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----------------+------------------+--------------------+--------------------+-----------------+-------+---------------+\n",
      "|user_location_country| country_encoded|user_location_city|        city_encoded|user_location_region|   region_encoded|channel|channel_encoded|\n",
      "+---------------------+----------------+------------------+--------------------+--------------------+-----------------+-------+---------------+\n",
      "|                   19|(217,[43],[1.0])|              1454|(18793,[5945],[1.0])|                  58|(858,[153],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                   66| (217,[0],[1.0])|             38899| (18793,[599],[1.0])|                 174|  (858,[0],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                   66| (217,[0],[1.0])|             31674| (18793,[365],[1.0])|                 442|  (858,[3],[1.0])|      0| (10,[1],[1.0])|\n",
      "|                   66| (217,[0],[1.0])|             35390|   (18793,[8],[1.0])|                 442|  (858,[3],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                   66| (217,[0],[1.0])|              9890|  (18793,[54],[1.0])|                 174|  (858,[0],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                   66| (217,[0],[1.0])|              9890|  (18793,[54],[1.0])|                 174|  (858,[0],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                   66| (217,[0],[1.0])|              5890|(18793,[5277],[1.0])|                 363| (858,[12],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                   66| (217,[0],[1.0])|             50661| (18793,[113],[1.0])|                 246| (858,[62],[1.0])|      1| (10,[2],[1.0])|\n",
      "|                  205| (217,[1],[1.0])|             46963|  (18793,[27],[1.0])|                 385| (858,[17],[1.0])|      0| (10,[1],[1.0])|\n",
      "|                  205| (217,[1],[1.0])|              9913| (18793,[116],[1.0])|                 354|  (858,[2],[1.0])|      5| (10,[4],[1.0])|\n",
      "|                  205| (217,[1],[1.0])|              9913| (18793,[116],[1.0])|                 354|  (858,[2],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                  205| (217,[1],[1.0])|              9913| (18793,[116],[1.0])|                 354|  (858,[2],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                  205| (217,[1],[1.0])|              9913| (18793,[116],[1.0])|                 354|  (858,[2],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                  205| (217,[1],[1.0])|              9913| (18793,[116],[1.0])|                 354|  (858,[2],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                  205| (217,[1],[1.0])|             51792| (18793,[122],[1.0])|                 354|  (858,[2],[1.0])|      2| (10,[3],[1.0])|\n",
      "|                  148|(217,[55],[1.0])|             51299| (18793,[370],[1.0])|                 328|(858,[208],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                   23| (217,[9],[1.0])|              4924|  (18793,[11],[1.0])|                  48| (858,[21],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                  205| (217,[1],[1.0])|             36086|   (18793,[4],[1.0])|                 135|  (858,[7],[1.0])|      9| (10,[0],[1.0])|\n",
      "|                   69| (217,[3],[1.0])|             41949|   (18793,[7],[1.0])|                 761| (858,[41],[1.0])|      4| (10,[6],[1.0])|\n",
      "|                   69| (217,[3],[1.0])|             41949|   (18793,[7],[1.0])|                 761| (858,[41],[1.0])|      4| (10,[6],[1.0])|\n",
      "+---------------------+----------------+------------------+--------------------+--------------------+-----------------+-------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "\n",
    "# Creating StringIndexer objects for each categorical variable\n",
    "indexer_country = StringIndexer(inputCol=\"user_location_country\", outputCol=\"country_index\")\n",
    "indexer_city = StringIndexer(inputCol=\"user_location_city\", outputCol=\"city_index\")\n",
    "indexer_region = StringIndexer(inputCol=\"user_location_region\", outputCol=\"region_index\")\n",
    "indexer_channel = StringIndexer(inputCol=\"channel\", outputCol=\"channel_index\")\n",
    "\n",
    "# Fitting the StringIndexer objects on the data\n",
    "indexer_model_country = indexer_country.fit(df_hotel)\n",
    "indexer_model_city = indexer_city.fit(df_hotel)\n",
    "indexer_model_region = indexer_region.fit(df_hotel)\n",
    "indexer_model_channel = indexer_channel.fit(df_hotel)\n",
    "\n",
    "# Transforming the data using the StringIndexer objects\n",
    "df_hotel_indexed = indexer_model_country.transform(df_hotel)\n",
    "df_hotel_indexed = indexer_model_city.transform(df_hotel_indexed)\n",
    "df_hotel_indexed = indexer_model_region.transform(df_hotel_indexed)\n",
    "df_hotel_indexed = indexer_model_channel.transform(df_hotel_indexed)\n",
    "\n",
    "# Creating OneHotEncoder objects for each categorical variable\n",
    "encoder_country = OneHotEncoder(inputCol=\"country_index\", outputCol=\"country_encoded\")\n",
    "encoder_city = OneHotEncoder(inputCol=\"city_index\", outputCol=\"city_encoded\")\n",
    "encoder_region = OneHotEncoder(inputCol=\"region_index\", outputCol=\"region_encoded\")\n",
    "encoder_channel = OneHotEncoder(inputCol=\"channel_index\", outputCol=\"channel_encoded\")\n",
    "\n",
    "# Fitting the OneHotEncoder objects on the data\n",
    "encoder_model_country = encoder_country.fit(df_hotel_indexed)\n",
    "encoder_model_city = encoder_city.fit(df_hotel_indexed)\n",
    "encoder_model_region = encoder_region.fit(df_hotel_indexed)\n",
    "encoder_model_channel = encoder_channel.fit(df_hotel_indexed)\n",
    "\n",
    "# Transforming the data using the OneHotEncoder objects\n",
    "df_hotel_encoded = encoder_model_country.transform(df_hotel_indexed)\n",
    "df_hotel_encoded = encoder_model_city.transform(df_hotel_encoded)\n",
    "df_hotel_encoded = encoder_model_region.transform(df_hotel_encoded)\n",
    "df_hotel_encoded = encoder_model_channel.transform(df_hotel_encoded)\n",
    "\n",
    "# Displaying the encoded data\n",
    "df_hotel_encoded.select(\"user_location_country\", \"country_encoded\", \"user_location_city\", \"city_encoded\", \"user_location_region\", \"region_encoded\", \"channel\", \"channel_encoded\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15e7cdd-3544-4996-bd4e-7564e409c3a2",
   "metadata": {},
   "source": [
    "# Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d860d888-ae3a-4f77-9967-9de7f3af5a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            features|     scaled_features|\n",
      "+--------------------+--------------------+\n",
      "|[5.0,2.0,2.0,2.0,...|[1.58748856634699...|\n",
      "|[8.0,1.0,1.0,2.0,...|[2.53998170615518...|\n",
      "|[2.0,1.0,1.0,2.0,...|[0.63499542653879...|\n",
      "|[4.0,1.0,1.0,2.0,...|[1.26999085307759...|\n",
      "|[1.0,1.0,1.0,2.0,...|[0.31749771326939...|\n",
      "|[2.0,1.0,1.0,2.0,...|[0.63499542653879...|\n",
      "|[8.0,1.0,1.0,2.0,...|[2.53998170615518...|\n",
      "|[1.0,1.0,4.0,4.0,...|[0.31749771326939...|\n",
      "|[1.0,2.0,1.0,2.0,...|[0.31749771326939...|\n",
      "|[4.0,1.0,1.0,1.0,...|[1.26999085307759...|\n",
      "|[4.0,2.0,1.0,1.0,...|[1.26999085307759...|\n",
      "|[3.0,1.0,1.0,1.0,...|[0.95249313980819...|\n",
      "|[2.0,1.0,1.0,1.0,...|[0.63499542653879...|\n",
      "|[2.0,1.0,1.0,1.0,...|[0.63499542653879...|\n",
      "|[1.0,1.0,1.0,1.0,...|[0.31749771326939...|\n",
      "|[5.0,1.0,2.0,2.0,...|[1.58748856634699...|\n",
      "|[5.0,1.0,1.0,2.0,...|[1.58748856634699...|\n",
      "|[4.0,4.0,1.0,3.0,...|[1.26999085307759...|\n",
      "|[4.0,1.0,1.0,1.0,...|[1.26999085307759...|\n",
      "|[4.0,1.0,1.0,1.0,...|[1.26999085307759...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler, VectorAssembler\n",
    "\n",
    "# Creating a VectorAssembler to assemble the features into a single vector\n",
    "vectorAssembler = VectorAssembler(inputCols=[\"num_nights\", \"cnt\", \"srch_rm_cnt\", \"srch_adults_cnt\", \"srch_children_cnt\"], outputCol=\"features\")\n",
    "df_hotel = vectorAssembler.transform(df_hotel)\n",
    "\n",
    "# Creating a StandardScaler object to scale the features\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "\n",
    "# Fitting the StandardScaler on the data\n",
    "scaler_model = scaler.fit(df_hotel)\n",
    "\n",
    "# Transforming the data using the StandardScaler\n",
    "df_hotel_scaled = scaler_model.transform(df_hotel)\n",
    "\n",
    "# Displaying the scaled data\n",
    "df_hotel_scaled.select(\"features\", \"scaled_features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5f957b-b618-4564-8be1-b8873902aa22",
   "metadata": {},
   "source": [
    "## Doing Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b410a8d8-5c6b-476c-a64e-da1cbcda2387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|  assembled_features|     scaled_features|\n",
      "+--------------------+--------------------+\n",
      "|[5.0,2.0,2.0,2.0,...|[1.58748856634699...|\n",
      "|[8.0,1.0,1.0,2.0,...|[2.53998170615518...|\n",
      "|[2.0,1.0,1.0,2.0,...|[0.63499542653879...|\n",
      "|[4.0,1.0,1.0,2.0,...|[1.26999085307759...|\n",
      "|[1.0,1.0,1.0,2.0,...|[0.31749771326939...|\n",
      "|[2.0,1.0,1.0,2.0,...|[0.63499542653879...|\n",
      "|[8.0,1.0,1.0,2.0,...|[2.53998170615518...|\n",
      "|[1.0,1.0,4.0,4.0,...|[0.31749771326939...|\n",
      "|[1.0,2.0,1.0,2.0,...|[0.31749771326939...|\n",
      "|[4.0,1.0,1.0,1.0,...|[1.26999085307759...|\n",
      "|[4.0,2.0,1.0,1.0,...|[1.26999085307759...|\n",
      "|[3.0,1.0,1.0,1.0,...|[0.95249313980819...|\n",
      "|[2.0,1.0,1.0,1.0,...|[0.63499542653879...|\n",
      "|[2.0,1.0,1.0,1.0,...|[0.63499542653879...|\n",
      "|[1.0,1.0,1.0,1.0,...|[0.31749771326939...|\n",
      "|[5.0,1.0,2.0,2.0,...|[1.58748856634699...|\n",
      "|[5.0,1.0,1.0,2.0,...|[1.58748856634699...|\n",
      "|[4.0,4.0,1.0,3.0,...|[1.26999085307759...|\n",
      "|[4.0,1.0,1.0,1.0,...|[1.26999085307759...|\n",
      "|[4.0,1.0,1.0,1.0,...|[1.26999085307759...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler, StandardScaler\n",
    "\n",
    "# Creating StringIndexer objects for each categorical variable\n",
    "indexer_country = StringIndexer(inputCol=\"user_location_country\", outputCol=\"country_index\")\n",
    "indexer_city = StringIndexer(inputCol=\"user_location_city\", outputCol=\"city_index\")\n",
    "indexer_region = StringIndexer(inputCol=\"user_location_region\", outputCol=\"region_index\")\n",
    "indexer_channel = StringIndexer(inputCol=\"channel\", outputCol=\"channel_index\")\n",
    "\n",
    "# Creating OneHotEncoder objects for each categorical variable\n",
    "encoder_country = OneHotEncoder(inputCol=\"country_index\", outputCol=\"country_encoded\")\n",
    "encoder_city = OneHotEncoder(inputCol=\"city_index\", outputCol=\"city_encoded\")\n",
    "encoder_region = OneHotEncoder(inputCol=\"region_index\", outputCol=\"region_encoded\")\n",
    "encoder_channel = OneHotEncoder(inputCol=\"channel_index\", outputCol=\"channel_encoded\")\n",
    "\n",
    "# Creating a VectorAssembler to assemble the features into a single vector\n",
    "vectorAssembler = VectorAssembler(inputCols=[\"num_nights\", \"cnt\", \"srch_rm_cnt\", \"srch_adults_cnt\", \"srch_children_cnt\"], outputCol=\"assembled_features\")\n",
    "df_hotel_assembled = vectorAssembler.transform(df_hotel_encoded)\n",
    "\n",
    "# Creating a StandardScaler object to scale the features\n",
    "scaler = StandardScaler(inputCol=\"assembled_features\", outputCol=\"scaled_features\")\n",
    "\n",
    "# Fitting the StandardScaler on the data\n",
    "scaler_model = scaler.fit(df_hotel_assembled)\n",
    "\n",
    "# Transforming the data using the StandardScaler\n",
    "df_hotel_scaled = scaler_model.transform(df_hotel_assembled)\n",
    "\n",
    "# Displaying the scaled data\n",
    "df_hotel_scaled.select(\"assembled_features\", \"scaled_features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c383b0-bac2-403f-b7bf-e53742631b90",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1674cc59-83ba-4d5c-ae85-1219712a8d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Criando um vetor com os atributos que serão usados para fazer as recomendações\n",
    "vectorAssembler = VectorAssembler(inputCols=[\"num_nights\", \"cnt\", \"srch_rm_cnt\", \"srch_adults_cnt\", \"srch_children_cnt\", \"channel\", \"is_mobile\", \"is_booking\", \"is_package\", \"user_location_country\", \"user_location_city\", \"user_location_region\", \"scaled_features\"], outputCol=\"features\")\n",
    "df_hotels = vectorAssembler.transform(df_hotel_scaled)\n",
    "\n",
    "# Separando os dados em conjuntos de treinamento e teste\n",
    "#(training, test) = df_hotels.randomSplit([0.8, 0.2])\n",
    "\n",
    "training = df_hotels.sampleBy(\"is_booking\", fractions={0: 0.8, 1: 0.8}, seed=42)\n",
    "test = df_hotels.subtract(training)\n",
    "\n",
    "\n",
    "# Configurando o modelo ALS (Alternating Least Squares) para fazer as recomendações\n",
    "als = ALS(userCol=\"user_id\", itemCol=\"Id_hotel\", ratingCol=\"is_booking\", coldStartStrategy=\"drop\")\n",
    "model = als.fit(training)\n",
    "\n",
    "recommendations = model.recommendForAllUsers(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1f9b418-571d-4e8b-bad2-d0af33dd4073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------------------------------------------------------------------------------------------------+\n",
      "|user_id|recommendations                                                                                               |\n",
      "+-------+--------------------------------------------------------------------------------------------------------------+\n",
      "|336709 |[{0, 0.0}, {10, 0.0}, {20, 0.0}, {30, 0.0}, {40, 0.0}, {50, 0.0}, {60, 0.0}, {-319, 0.0}, {1, 0.0}, {11, 0.0}]|\n",
      "+-------+--------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "recommendations.filter(recommendations.user_id == 336709).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e79a3bd6-84bb-47af-8266-dd5a50be7c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------\n",
      " num_nights            | 5                    \n",
      " cnt                   | 2                    \n",
      " srch_rm_cnt           | 2                    \n",
      " srch_adults_cnt       | 2                    \n",
      " srch_children_cnt     | 4                    \n",
      " channel               | 9                    \n",
      " is_mobile             | 0                    \n",
      " is_booking            | 0                    \n",
      " is_package            | 0                    \n",
      " user_location_country | 19                   \n",
      " user_location_city    | 1454                 \n",
      " user_location_region  | 58                   \n",
      " Id_hotel              | 5                    \n",
      " user_id               | 336350               \n",
      " country_index         | 43.0                 \n",
      " city_index            | 5945.0               \n",
      " region_index          | 153.0                \n",
      " channel_index         | 0.0                  \n",
      " country_encoded       | (217,[43],[1.0])     \n",
      " city_encoded          | (18793,[5945],[1.0]) \n",
      " region_encoded        | (858,[153],[1.0])    \n",
      " channel_encoded       | (10,[0],[1.0])       \n",
      " assembled_features    | [5.0,2.0,2.0,2.0,... \n",
      " scaled_features       | [1.58748856634699... \n",
      " features              | [5.0,2.0,2.0,2.0,... \n",
      "-RECORD 1-------------------------------------\n",
      " num_nights            | 8                    \n",
      " cnt                   | 1                    \n",
      " srch_rm_cnt           | 1                    \n",
      " srch_adults_cnt       | 2                    \n",
      " srch_children_cnt     | 0                    \n",
      " channel               | 9                    \n",
      " is_mobile             | 0                    \n",
      " is_booking            | 0                    \n",
      " is_package            | 1                    \n",
      " user_location_country | 66                   \n",
      " user_location_city    | 38899                \n",
      " user_location_region  | 174                  \n",
      " Id_hotel              | 8                    \n",
      " user_id               | 336599               \n",
      " country_index         | 0.0                  \n",
      " city_index            | 599.0                \n",
      " region_index          | 0.0                  \n",
      " channel_index         | 0.0                  \n",
      " country_encoded       | (217,[0],[1.0])      \n",
      " city_encoded          | (18793,[599],[1.0])  \n",
      " region_encoded        | (858,[0],[1.0])      \n",
      " channel_encoded       | (10,[0],[1.0])       \n",
      " assembled_features    | [8.0,1.0,1.0,2.0,... \n",
      " scaled_features       | [2.53998170615518... \n",
      " features              | [8.0,1.0,1.0,2.0,... \n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_hotels.show(2,vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee91d409-3da7-420b-bef5-30e4b26a86a6",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f4c6b0-adf1-4c84-a1ad-94399aa8385a",
   "metadata": {},
   "source": [
    "# Interpretando Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d94071-35a7-4bbe-a3dd-fba24558d7a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b36bcc08-57ea-4561-8171-8b71b29eb678",
   "metadata": {},
   "source": [
    "# Using the model with new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3665507a-7d49-4395-9616-a6d143204bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------+\n",
      "|user_id|recommendations|\n",
      "+-------+---------------+\n",
      "+-------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "# criar um novo DataFrame para um novo usuário\n",
    "new_user = Row(user_id=999, num_nights=3, cnt=2, srch_rm_cnt=1, srch_adults_cnt=2, srch_children_cnt=0,\n",
    "               channel=1, is_mobile=0, is_booking=0, is_package=1, user_location_country=50, user_location_city=1234,\n",
    "               user_location_region=123)\n",
    "\n",
    "new_user_df = spark.createDataFrame([new_user])\n",
    "\n",
    "# gerar recomendações para o novo usuário\n",
    "new_user_recs = model.recommendForUserSubset(new_user_df, 10)\n",
    "new_user_recs.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c773e41d-c512-45b0-a460-85d3691b54be",
   "metadata": {},
   "source": [
    "# Validar o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b95f7d-419d-4d65-8ca4-a33c371a6839",
   "metadata": {},
   "source": [
    "## Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "706f7d57-38fb-447c-8f1d-d7d090691f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:33:00 WARN DAGScheduler: Broadcasting large task binary with size 1586.6 KiB\n",
      "23/04/07 12:33:00 WARN DAGScheduler: Broadcasting large task binary with size 1608.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:33:02 WARN DAGScheduler: Broadcasting large task binary with size 1781.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 696:>                                                        (0 + 6) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:33:04 WARN DAGScheduler: Broadcasting large task binary with size 1657.6 KiB\n",
      "23/04/07 12:33:04 WARN DAGScheduler: Broadcasting large task binary with size 1722.2 KiB\n",
      "Accuracy: 81.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "predictions = model.transform(test)\n",
    "predictions = predictions.withColumn(\"prediction\", col(\"prediction\").cast(\"double\"))\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"is_booking\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy: {:.2%}\".format(accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bcda50-d6e4-4052-b7f9-f1ca99306feb",
   "metadata": {},
   "source": [
    "## Precision Recall F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fc38b981-0457-4b08-8581-a4b66dc2a934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:28 WARN DAGScheduler: Broadcasting large task binary with size 1586.6 KiB\n",
      "23/04/07 12:35:28 WARN DAGScheduler: Broadcasting large task binary with size 1608.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:30 WARN DAGScheduler: Broadcasting large task binary with size 1781.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 784:============================>                            (3 + 3) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:32 WARN DAGScheduler: Broadcasting large task binary with size 1657.6 KiB\n",
      "23/04/07 12:35:32 WARN DAGScheduler: Broadcasting large task binary with size 1722.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:32 WARN DAGScheduler: Broadcasting large task binary with size 1586.6 KiB\n",
      "23/04/07 12:35:32 WARN DAGScheduler: Broadcasting large task binary with size 1608.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:33 WARN DAGScheduler: Broadcasting large task binary with size 1781.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 872:>                                                        (0 + 6) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:35 WARN DAGScheduler: Broadcasting large task binary with size 1657.6 KiB\n",
      "23/04/07 12:35:35 WARN DAGScheduler: Broadcasting large task binary with size 1722.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:35 WARN DAGScheduler: Broadcasting large task binary with size 1586.6 KiB\n",
      "23/04/07 12:35:35 WARN DAGScheduler: Broadcasting large task binary with size 1608.1 KiB\n",
      "23/04/07 12:35:36 WARN DAGScheduler: Broadcasting large task binary with size 1781.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 960:>                                                        (0 + 6) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:37 WARN DAGScheduler: Broadcasting large task binary with size 1657.6 KiB\n",
      "23/04/07 12:35:38 WARN DAGScheduler: Broadcasting large task binary with size 1722.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:38 WARN DAGScheduler: Broadcasting large task binary with size 1586.6 KiB\n",
      "23/04/07 12:35:38 WARN DAGScheduler: Broadcasting large task binary with size 1608.1 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:39 WARN DAGScheduler: Broadcasting large task binary with size 1781.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1048:>                                                       (0 + 6) / 6]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 12:35:40 WARN DAGScheduler: Broadcasting large task binary with size 1657.6 KiB\n",
      "23/04/07 12:35:40 WARN DAGScheduler: Broadcasting large task binary with size 1722.2 KiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Avalia as previsões do modelo nos dados de teste\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"is_booking\")\n",
    "accuracy = evaluator.evaluate(predictions, {evaluator.metricName: \"accuracy\"})\n",
    "precision = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedPrecision\"})\n",
    "recall = evaluator.evaluate(predictions, {evaluator.metricName: \"weightedRecall\"})\n",
    "f1_score = evaluator.evaluate(predictions, {evaluator.metricName: \"f1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d4a7f5a3-e426-49a4-9019-d503f3ad2dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:  0.8161745233050848\n",
      "Precision:  0.85947772305961\n",
      "Recall:  0.8161745233050848\n",
      "f1_score 0.8372665896893304\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"f1_score\", f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63caf86-795c-4f77-a744-b85d46886c66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20710791-ecfd-43df-be9e-46eb641fe726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a147efc-e5f0-437f-b7a1-3ad47ea1de68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bf7f30-0af0-46fc-bea1-1a17c5cf5612",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e1f056-0ca7-494a-91c2-4c18807132ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c9cc7d-010f-4003-963a-fb72df6e606c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68c474e6-bb76-43aa-a080-b40d47dfa05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "\n",
    "# Criando um vetor com os atributos que serão usados para fazer as recomendações\n",
    "vectorAssembler = VectorAssembler(inputCols=[\"num_nights\", \"cnt\", \"srch_rm_cnt\", \"srch_adults_cnt\", \"srch_children_cnt\", \"channel\",\"is_mobile\", \"is_booking\", \"is_package\", \"user_location_country\", \"user_location_city\", \"user_location_region\"], outputCol=\"features\")\n",
    "df_hotels = vectorAssembler.transform(df_hotel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb6f8fb5-d362-4f69-a3d6-5236dc89a77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/04/07 11:11:54 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "23/04/07 11:11:54 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "23/04/07 11:11:54 WARN InstanceBuilder$NativeLAPACK: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n"
     ]
    }
   ],
   "source": [
    "# Separando os dados em conjuntos de treinamento e teste\n",
    "(training, test) = df_hotels.randomSplit([0.8, 0.2])\n",
    "\n",
    "\n",
    "# Configurando o modelo ALS (Alternating Least Squares) para fazer as recomendações\n",
    "als = ALS(userCol=\"user_id\", itemCol=\"Id_hotel\", ratingCol=\"is_booking\", coldStartStrategy=\"drop\")\n",
    "model = als.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e808b9aa-2a43-4928-b294-140e13593657",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = model.recommendForAllUsers(10) #Não usem esta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a206fe5-e22b-4ee2-ae59-0c10ca11a2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 105:==============================>                      (58 + 10) / 100]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------------------------------------------------------------------------------------+\n",
      "|user_id|recommendations                                                                                                 |\n",
      "+-------+----------------------------------------------------------------------------------------------------------------+\n",
      "|336350 |[{-260, 0.0}, {0, 0.0}, {10, 0.0}, {20, 0.0}, {30, 0.0}, {40, 0.0}, {50, 0.0}, {60, 0.0}, {-309, 0.0}, {1, 0.0}]|\n",
      "+-------+----------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "recommendations.filter(recommendations.user_id == 336350).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6523e234-26c3-4524-b3fa-1a6c2f652c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------------------------\n",
      " num_nights            | 5                    \n",
      " cnt                   | 2                    \n",
      " srch_rm_cnt           | 2                    \n",
      " srch_adults_cnt       | 2                    \n",
      " srch_children_cnt     | 4                    \n",
      " channel               | 9                    \n",
      " is_mobile             | 0                    \n",
      " is_booking            | 0                    \n",
      " is_package            | 0                    \n",
      " user_location_country | 19                   \n",
      " user_location_city    | 1454                 \n",
      " Id_hotel              | 5                    \n",
      " user_location_region  | 58                   \n",
      " user_id               | 336350               \n",
      " features              | [5.0,2.0,2.0,2.0,... \n",
      "-RECORD 1-------------------------------------\n",
      " num_nights            | 8                    \n",
      " cnt                   | 1                    \n",
      " srch_rm_cnt           | 1                    \n",
      " srch_adults_cnt       | 2                    \n",
      " srch_children_cnt     | 0                    \n",
      " channel               | 9                    \n",
      " is_mobile             | 0                    \n",
      " is_booking            | 0                    \n",
      " is_package            | 1                    \n",
      " user_location_country | 66                   \n",
      " user_location_city    | 38899                \n",
      " Id_hotel              | 8                    \n",
      " user_location_region  | 174                  \n",
      " user_id               | 336599               \n",
      " features              | [8.0,1.0,1.0,2.0,... \n",
      "-RECORD 2-------------------------------------\n",
      " num_nights            | 2                    \n",
      " cnt                   | 1                    \n",
      " srch_rm_cnt           | 1                    \n",
      " srch_adults_cnt       | 2                    \n",
      " srch_children_cnt     | 0                    \n",
      " channel               | 0                    \n",
      " is_mobile             | 0                    \n",
      " is_booking            | 0                    \n",
      " is_package            | 0                    \n",
      " user_location_country | 66                   \n",
      " user_location_city    | 31674                \n",
      " Id_hotel              | 2                    \n",
      " user_location_region  | 442                  \n",
      " user_id               | 336709               \n",
      " features              | [2.0,1.0,1.0,2.0,... \n",
      "-RECORD 3-------------------------------------\n",
      " num_nights            | 4                    \n",
      " cnt                   | 1                    \n",
      " srch_rm_cnt           | 1                    \n",
      " srch_adults_cnt       | 2                    \n",
      " srch_children_cnt     | 0                    \n",
      " channel               | 9                    \n",
      " is_mobile             | 0                    \n",
      " is_booking            | 0                    \n",
      " is_package            | 1                    \n",
      " user_location_country | 66                   \n",
      " user_location_city    | 35390                \n",
      " Id_hotel              | 4                    \n",
      " user_location_region  | 442                  \n",
      " user_id               | 336709               \n",
      " features              | [4.0,1.0,1.0,2.0,... \n",
      "-RECORD 4-------------------------------------\n",
      " num_nights            | 1                    \n",
      " cnt                   | 1                    \n",
      " srch_rm_cnt           | 1                    \n",
      " srch_adults_cnt       | 2                    \n",
      " srch_children_cnt     | 0                    \n",
      " channel               | 9                    \n",
      " is_mobile             | 0                    \n",
      " is_booking            | 0                    \n",
      " is_package            | 0                    \n",
      " user_location_country | 66                   \n",
      " user_location_city    | 9890                 \n",
      " Id_hotel              | 1                    \n",
      " user_location_region  | 174                  \n",
      " user_id               | 336885               \n",
      " features              | [1.0,1.0,1.0,2.0,... \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_hotels.show(5,vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a51b54-778c-491c-8992-fc53c945af51",
   "metadata": {},
   "source": [
    "- Como Normailzar os Dados\n",
    "- Como validar o modelo, calcular performance\n",
    "- Como ter a lista de hoteis recomendados\n",
    "- Tirar cnt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50720d6-8397-46c0-b1f4-faa78f4dd2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
